---
title: Обзор примера отслеживания взгляда
description: Пример создания эйетраккинг в МРТК
author: CDiaz-MS
ms.author: cadia
ms.date: 01/12/2021
keywords: Unity, HoloLens, HoloLens 2, Mixed Reality, разработка, МРТК, Эйетраккинг,
ms.openlocfilehash: b5fd3ee35e54c54f2f6b21dc1ce53625c68f65b4
ms.sourcegitcommit: c0ba7d7bb57bb5dda65ee9019229b68c2ee7c267
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 05/19/2021
ms.locfileid: "110144685"
---
# <a name="eye-tracking-examples"></a>Примеры отслеживания взгляда

В этом разделе описывается, как быстро приступить к работе с отслеживанием взгляда в МРТК, создав МРТК примеры отслеживания взглядов (Asset/МРТК/examples/демонстрация/Эйетраккинг).
Эти примеры позволяют увидеть одну из наших новых возможностей ввода Magical: **Отслеживание глаз**!
Демонстрация включает в себя различные варианты использования, от неявных активаций на основе взгляда до того, как легко объединять информацию о том, что вы видите с помощью **голоса** и **руки** .
Это позволяет пользователям быстро и без труда выбирать и перемещать holographic содержимое в своем представлении, просто просматривая цель и произнося _«SELECT»_ или выполнив жест руки.
В демонстрационных роликах также содержится пример прокрутки, панорамы и масштабирования текста и изображений на планшете.
Наконец, приведен пример для записи и визуализации визуального внимания пользователя на 2D-планшете.
В следующем разделе вы найдете дополнительные сведения о том, какие из различных примеров в примере пакета отслеживания взгляда МРТК (Assets/МРТК/examples/Samples/Эйетраккинг) включают:

![Список сцен отслеживания взгляда](../images/eye-tracking/mrtk_et_list_et_scenes.jpg)

В следующем разделе приведены краткие сведения о том, что представляют собой демонстрационные сцены индивидуального отслеживания взгляда.
Демонстрационные сцены отслеживания взгляда МРТК [загружаются аддитивным](https://docs.unity3d.com/ScriptReference/SceneManagement.LoadSceneMode.Additive.html), что мы объясним ниже, как настроить.

## <a name="overview-of-the-eye-tracking-demo-samples"></a>Обзор демонстрационных примеров по отслеживанию взглядов

### <a name="eye-supported-target-selection"></a>[**Глаз — поддерживаемый Выбор целевого объекта**](../input/eye-tracking/eye-tracking-target-selection.md)

В этом учебнике демонстрируется простота доступа к данным взгляда на выбор целевых объектов.
Он содержит пример для незаметной, но мощной обратной связи, чтобы предоставить пользователю уверенность в том, что целевой объект не является огромным.
Кроме того, существует простой пример интеллектуальных уведомлений, которые автоматически исчезают после чтения.

**Сводка**: быстрый и простой выбор целевых объектов с помощью сочетания глаз, голоса и руки ввода.

### <a name="eye-supported-navigation"></a>[**Поддерживаемая Навигация**](../input/eye-tracking/eye-tracking-navigation.md)

Представьте, что вы читаете какую-либо информацию на удаленном дисплее или на устройстве чтения, а когда дойдете до конца отображаемого текста, текст автоматически прокручивается, чтобы показать больше содержимого.
Или как насчет волшебного масштабирования непосредственно в сторону того, где вы искали?
Ниже приведены некоторые примеры, представленные в этом учебнике для навигации с поддержкой взгляда.
Кроме того, есть пример, позволяющий бесплатно вращать трехмерные голограммы, автоматически поворачивать их в соответствии с текущим фокусом.

**Сводка**: прокрутка, сдвиг, масштаб, трехмерное вращение с помощью сочетания глаз, голоса и руки ввода.

### <a name="eye-supported-positioning"></a>[**Позиционирование с поддержкой глаз**](../input/eye-tracking/eye-tracking-eyes-and-hands.md)

В этом учебнике показан входной сценарий с названием «датировано» [,](https://youtu.be/CbIn8p4_4CQ) с помощью которого можно вернуться к исследованию из лаборатории мультимедиа MIT в начале 1980 с глазом, рукой и голосовым входом.
Идея проста: Воспользуйтесь преимуществами ваших глаз для быстрого выбора целевых объектов и позиционирования.
Просто взгляните на голограмму и скажите _«поместить сюда_», Взгляните на место, где вы хотите его разместить, и скажите _«!»_.
Для более точного размещения голограммы можно использовать дополнительные входные данные из руки, голоса или контроллеров.

**Сводка**: размещение голограмм с помощью глаз, голоса и руки (*перетаскивание*). Поддерживаемые в глаза ползунки с использованием глаз + руки.

### <a name="visualization-of-visual-attention"></a>**Визуализация визуального внимания**

Данные в зависимости от того, где пользователи выглядят, делают чрезвычайно мощным средством для оценки удобства использования проекта и выявления проблем в эффективных рабочих потоках.
В этом учебнике рассматриваются различные визуализации отслеживания взгляда и их соответствие различным потребностям.
Мы предоставляем основные примеры для ведения журнала и загрузки данных отслеживания взгляда и примеры их визуализации.

**Сводка**. двухмерная схема внимания (тепловые карты) на планшетах. Запись & воспроизведением данных отслеживания взгляда.

## <a name="setting-up-the-mrtk-eye-tracking-samples"></a>Настройка образцов отслеживания взгляда МРТК

### <a name="prerequisites"></a>Предварительные требования

Обратите внимание, что для использования примеров отслеживания взгляда на устройстве требуется HoloLens 2 и пример пакета приложения, построенный с помощью функции "взгляд ввода", в AppXManifest пакета.

Чтобы использовать эти образцы отслеживания взгляда на устройстве, перед созданием приложения в Visual Studio обязательно выполните следующие [действия](../input/eye-tracking/eye-tracking-basic-setup.md#testing-your-unity-app-on-a-hololens-2) .

### <a name="1-load-eyetrackingdemo-00-rootsceneunity"></a>1. Load Эйетраккингдемо-00-Рутсцене. Unity

*Эйетраккингдемо-00-рутсцене* — это базовая (_корневая_) сцена, в которую входят все основные компоненты мртк.
Это сцена, которую необходимо загрузить в первую очередь и из которой будут запускаться демонстрации отслеживания взгляда.
Он содержит графическое меню сцены, позволяющее легко переключаться между различными образцами отслеживания взгляда, которые будут [загружаться аддитивно](https://docs.unity3d.com/ScriptReference/SceneManagement.LoadSceneMode.Additive.html).

![Меню "сцена" в примере "Отслеживание глаз"](../images/eye-tracking/mrtk_et_scenemenu.jpg)

В корневой сцене содержится несколько основных компонентов, которые будут сохраняться во всех аддитивных сценах, таких как настроенные профили МРТК и камера сцены.
_Микседреалитибасиксценесетуп_ (см. снимок экрана ниже) включает сценарий, который автоматически загружает сцену, на которую указывает ссылка при запуске.
По умолчанию это _эйетраккингдемо-02-таржетселектион_.  

![Пример сценария Онлоадстартсцене](../images/eye-tracking/mrtk_et_onloadstartscene.jpg)

### <a name="2-adding-scenes-to-the-build-menu"></a>2. добавление сцен в меню "сборка"

Чтобы загрузить Аддитивные сцены во время выполнения, необходимо добавить эти сцены в _параметры сборки — сначала > сцены в меню Сборка_ .
Важно, чтобы корневая сцена отображалась в виде первой сцены в списке:

![Меню сцены параметров сборки для образцов отслеживания взгляда](../images/eye-tracking/mrtk_et_build_settings.jpg)

### <a name="3-play-the-eye-tracking-samples-in-the-unity-editor"></a>3. Воспроизведение образцов отслеживания взгляда в редакторе Unity

После добавления сцен отслеживания взгляда в параметры сборки и загрузки _эйетраккингдемо-00-рутсцене_ есть еще одна вещь, которую вы можете проверить: — это сценарий _онлоадстартсцене_ , присоединенный к _микседреалитибасиксценесетуп_ GameObject. Это позволяет корневой сцене понять, какая демонстрационная сцена должна быть загружена в первую очередь.

![Пример скрипта OnLoad_StartScene](../images/eye-tracking/mrtk_et_onloadstartscene.jpg)

Поехали! Нажмите _"Воспроизвести"_!
Должно отобразиться несколько драгоценных камней, а в верхней части — меню сцены.

![Пример снимка экрана с целевым объектом ET выбор сцены](../images/eye-tracking/mrtk_et_targetselect.png)

Кроме того, обратите внимание на небольшой полупрозрачный круг в центре игрового представления.
Это является индикатором (курсором) _имитации глаз_: просто нажмите _правую кнопку мыши_ и наведите указатель мыши, чтобы изменить его положение.
Когда курсор наведен на драгоценные камни, вы заметите, что он будет привязан к центру текущего драгоценного камень.
Это отличный способ проверки, если события запускаются ожидаемым образом при _поиске_ на целевом объекте.
Имейте в виду, что _имитация взгляда_ с помощью мыши — это довольно неплохое дополнение к нашим быстрому и непреднамеренному перемещению глаз.
Однако это очень удобно для тестирования базовой функциональности перед итерацией проекта, развернув его на устройстве HoloLens 2.
Возврат к нашему образцу сцены отслеживания взгляда: драгоценный камень поворачивается, пока он просматривается и может быть уничтожен «поиском» в нем и...

- Нажатие клавиши _Ввод_ (имитируется с произнесением "Select")
- Слово _"выбрать"_ в микрофон
- Удерживая нажатой клавишу _пробел_ для отображения имитации руки, нажмите левую кнопку мыши, чтобы выполнить имитацию сжатия.

Мы подробно рассмотрим, как можно достичь этих взаимодействий в учебнике [**Выбор целевого объекта с поддержкой взгляда**](../input/eye-tracking/eye-tracking-target-selection.md) .

При перемещении курсора вверх в верхнюю строку меню сцены вы заметите, что элемент, находящегося под указателем, выделит немного.
Выделенный в данный момент элемент можно выбрать с помощью одного из описанных выше методов фиксации (например, нажатием клавиши _Ввод_).
Таким образом можно переключаться между различными примерами сцен отслеживания взгляда.

### <a name="4-how-to-test-specific-sub-scenes"></a>4. тестирование конкретных подмонтажных кадров

При работе с конкретным сценарием Вы можете не захотеть использовать меню "сцена" каждый раз.
Вместо этого может потребоваться запустить непосредственно из сцены, над которой вы работаете в данный момент при нажатии кнопки _воспроизведения_ .
Это не проблема! Вот что можно сделать:

1. Загрузка _корневой_ сцены
2. В _корневой_ сцене отключите сценарий _"онлоадстартсцене"_ .
3. _Перетащите_ один из сцен теста отслеживания взгляда, описанный ниже (или любую другую сцену), в представление _иерархии_ , как показано на снимке экрана ниже.

    ![Пример для аддитивной сцены](../images/eye-tracking/mrtk_et_additivescene.jpg)

4. Нажмите кнопку _Воспроизведение_

Обратите внимание, что загрузка вспомогательной сцены, например, не является постоянной: это означает, что при развертывании приложения на устройстве HoloLens 2 будет загружена только корневая сцена (предполагая, что она отображается в верхней части параметров сборки).
Кроме того, при совместном использовании проекта с другими пользователями подпрограммы не загружаются автоматически.

---

Теперь, когда вы умеете работать с примерами МРТК для отслеживания взгляда, давайте продолжим углубляться в изучение того, как выбирать голограммы с глазами: [поддерживаемый Выбор целевого объекта](../input/eye-tracking/eye-tracking-target-selection.md).

---
[Вернуться к "Отслеживание взглядов в Микседреалититулкит"](../input/eye-tracking/eye-tracking-Main.md)
