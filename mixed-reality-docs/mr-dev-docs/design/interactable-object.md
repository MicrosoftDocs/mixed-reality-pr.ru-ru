---
title: Активный объект
description: Кнопка длиннее метафоры, используемой для активации события в 2D-абстрактном мире. В мире объемной смешанной реальности мы больше не должны беспокоиться об этом мире абстракции.
author: cre8ivepark
ms.author: v-hferrone
ms.date: 06/06/2019
ms.topic: article
keywords: Смешанная реальность, элементы управления, взаимодействие, Пользовательский интерфейс, UX
ms.openlocfilehash: 6458f4b1c80c8606d07d610f509ed610a0ca4268
ms.sourcegitcommit: 09599b4034be825e4536eeb9566968afd021d5f3
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 10/03/2020
ms.locfileid: "91691669"
---
# <a name="interactable-object"></a>Активный объект

![Объекты интерактибле](images/UX_Hero_Interactable.jpg)

Кнопка длиннее метафоры, используемой для активации события в 2D-абстрактном мире. В мире объемной смешанной реальности мы больше не должны беспокоиться об этом мире абстракции. Любой может быть **взаимодействующим объектом** , запускающим событие. Взаимодействующий объект может быть представлен любым из чашк кофе в таблице в виде всплывающей подсказки, плавающей в воздухе. Мы по-прежнему используем традиционные кнопки в определенных ситуациях, например в пользовательском интерфейсе диалогового окна. Визуальное представление кнопки зависит от контекста.

<br>

---


## <a name="important-properties-of-the-interactable-object"></a>Важные свойства взаимодействующего объекта

### <a name="visual-cues"></a>Визуальные подсказки

Визуальные подсказки — это подсистемы датчиков, получаемые глазом в виде освещения и обрабатываемые визуальной системой во время визуального восприятия. Так как визуальная система находится во многих виды цветов, особенно для людей, визуальные подсказки представляют собой большой источник информации о том, как воспринимается мир.

Поскольку holographic объектов смешиваются с реальной средой в смешанной реальности, может быть трудно понять, с какими объектами можно взаимодействовать. Для любых взаимодействующих объектов важно предоставить дифференцированные визуальные подсказки для каждого входного состояния. Это помогает пользователю понять, какая часть вашего интерфейса является взаимодействующей, и делает пользователя уверенным, используя согласованный метод взаимодействия.

<br>

---

### <a name="far-interactions"></a>Дальнее взаимодействие

Для любых объектов, с которыми пользователь может взаимодействовать с помощью элемента управления "взгляд, рука и луч контроллера движения", рекомендуется иметь разные визуальные подсказки для этих трех состояний входа:

:::row:::
    :::column:::
       ![интерактиблеобжект — состояния — по умолчанию](images/interactibleobject-states-default.jpg)<br>
       **Состояние по умолчанию (наблюдение)**<br>
        Состояние простоя объекта по умолчанию.
    Курсор не находится на объекте. Рука не обнаружена.
    :::column-end:::
    :::column:::
       ![интерактиблеобжект — целевое состояние](images/interactibleobject-states-targeted.jpg)<br>
        **Целевое состояние (наведение указателя)**<br>
        Когда объект ориентирован на курсор «взгляд», указатель мыши на палец или контроллер движения.
    Курсор находится на объекте. Обнаружена, готова.
    :::column-end:::
    :::column:::
       ![интерактиблеобжект-с нажатием состояния](images/interactibleobject-states-pressed.jpg)<br>
       **Нажатое состояние**<br>
        Когда объект нажимается с помощью жеста касания, нажмите кнопку "выбрать" для сенсорного экрана.
    Курсор находится на объекте. Обнаружена рука, касание воздуха.
    :::column-end:::
:::row-end:::

<br>

---

Вы можете использовать такие методы, как выделение или масштабирование, чтобы обеспечить визуальные подсказки для состояния ввода пользователя. В смешанной реальности можно найти примеры визуализации различных состояний ввода в меню "Пуск" и с кнопками панели приложений. 

Вот как эти состояния выглядят на **кнопке holographic** :

:::row:::
    :::column:::
       ![интерактиблеобжект — состояния — по умолчанию](images/MRTK_InteractableState-default.jpg)<br>
       **Состояние по умолчанию (наблюдение)**<br>
    :::column-end:::
    :::column:::
       ![интерактиблеобжект — целевое состояние](images/MRTK_InteractableState-targeted.jpg)<br>
        **Целевое состояние (наведение указателя)**<br>
    :::column-end:::
    :::column:::
       ![интерактиблеобжект-с нажатием состояния](images/MRTK_InteractableState-pressed.jpg)<br>
       **Нажатое состояние**<br>
    :::column-end:::
:::row-end:::

<br>

---

### <a name="near-interactions-direct"></a>Близкое взаимодействие (Direct) 

HoloLens 2 поддерживает вводные данные отслеживания, которые позволяют взаимодействовать с объектами. Без хаптик отзывов и более глубокого восприятия иногда может быть трудно определить, насколько далеко от руки покидает объект, или же вы его намерены касаться. Важно предоставить достаточно визуальных подсказок для передачи состояния объекта и, в частности, состояния ваших связей с этим объектом.

Используйте визуальную обратную связь, чтобы сообщить следующее:
* **По умолчанию (наблюдение)** : состояние простоя объекта по умолчанию.
* **Наведение указателя мыши** : когда руку приближается к голограмме, измените визуальные элементы так, чтобы они могли взаимодействовать с голограммами. 
* **Расстояние и точка взаимодействия** : как рука приближается к голограмме, вы отдаете отзыв о проектировании, чтобы сообщить о предполагаемой точке взаимодействия, а также о том, насколько далеко от объекта палец
* **Начало контакта** : измените визуальные элементы (светло, Color), чтобы сообщить о том, что произошло касание.
* Повышено **: изменение** визуальных элементов (светлое, цветное) при проходе на объект
* **Окончание связи** : изменение визуальных элементов (светлое, цветное) при завершении сенсорного ввода

<br>

---

:::row:::
    :::column:::
        ![Наведение (далеко)](images/640px-interactibleobject-states-near-hover.jpg)<br>
        **Наведение (далеко)**<br>
        Выделение на основе сходства руки.
    :::column-end:::
    :::column:::
        ![Наведение указателя мыши (вблизи)](images/640px-interactibleobject-states-near-hovernear.jpg)<br>
        **Наведение указателя мыши (вблизи)**<br>
        Выделяйте изменения размера в зависимости от расстояния от руки.
    :::column-end:::
:::row-end:::

:::row:::
    :::column:::
        ![Сенсорный ввод/нажатие](images/640px-interactibleobject-states-near-press.jpg)<br>
        **Сенсорный ввод/нажатие**<br>
        Визуальная и обратная связь.
    :::column-end:::
    :::column:::
        ![Осознавать](images/640px-interactibleobject-states-near-grasp.jpg)<br>
        **Осознавать**<br>
        Визуальная и обратная связь.
    :::column-end:::
:::row-end:::

<br>

<br>

---

[Кнопка в HoloLens 2](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/README_Button.html) представляет собой пример визуализации различных состояний взаимодействия.

:::row:::
    :::column:::
        ![по умолчанию](images/640px-interactibleobject-pressablebutton-default.jpg)<br>
        **Default**<br>
    :::column-end:::
    :::column:::
        ![Наведение](images/640px-interactibleobject-pressablebutton-hover.jpg)<br>
        **Наведение**<br>
        Показать эффекты освещения на основе близости.
    :::column-end:::
:::row-end:::

:::row:::
    :::column:::
        ![Сенсорный ввод](images/640px-interactibleobject-pressablebutton-touch.jpg)<br>
        **Сенсорный ввод**<br>
        Отображать эффекты Ripple.
    :::column-end:::
    :::column:::
        ![Сочетание клавиш](images/640px-interactibleobject-pressablebutton-press.jpg)<br>
        **Сочетание клавиш**<br>
        Переместите переднюю форму.
    :::column-end:::
:::row-end:::

<br>

---

:::row:::
    :::column:::
        ### <a name="the-ring-visual-cue-on-hololens-2br"></a>Визуальная подсказка кольца в HoloLens 2<br>
        В HoloLens 2 есть дополнительная визуальная подсказка, которая может помочь пользователю в восприятии глубины. Кольцо рядом с ним отображается и масштабируется по мере того, как прокрутка будет ближе к объекту. В конечном итоге, если достигнуто нажатое состояние, кольцо будет находиться в точке. Этот визуальный подход позволяет пользователю понять, насколько далеко они от объекта.<br>
        <br>
        *Цикл видео. пример визуальной обратной связи на основе сходства с ограничивающим прямоугольником*
    :::column-end:::
        :::column:::
        ![space](images/spacer-20x582.png)<br>
       ![Визуальный отзыв о близком к рукой](images/HoloLens2_Proximity.gif)<br>
    :::column-end:::
:::row-end:::


<br>

---


### <a name="audio-cues"></a>Звуковые подсказки

При прямом взаимодействии руки правильная обратная связь может значительно улучшить взаимодействие с пользователем. Используйте отзыв о звуке, чтобы сообщить следующее:
* **Начало контакта** : воспроизведение звука при начале сенсорного ввода
* **Окончание контакта** : воспроизведение звука в сенсорном конце
* **Начало захвата** : воспроизведение звука при начале
* **Конец захвата** : воспроизведение звука при завершении захвата

<br>

---

:::row:::
    :::column:::
        ### <a name="voice-commandingbr"></a>Голосовые команды<br>
        Для любых взаимодействующих объектов важно поддерживать альтернативные варианты взаимодействия. По умолчанию рекомендуется поддерживать [командную команду Voice](../out-of-scope/voice-design.md) для всех объектов, которые являются взаимодействующими. Чтобы улучшить возможность обнаружения, можно также предоставить подсказку во время наведения указателя мыши.<br>
        <br>
        *Изображение: подсказка для команды Voice*
    :::column-end:::
        :::column:::
       ![голосовое командое](images/640px-interactibleobject-voicecommand.png)<br>
    :::column-end:::
:::row-end:::


<br>

---


## <a name="sizing-recommendations"></a>Рекомендации относительно размеров 

Чтобы пользователи могли легко затронуть все взаимодействующие объекты, рекомендуется убедиться, что они соответствуют минимальному размеру (визуальный угол, часто измеряемый в градусах визуальной дуги) в зависимости от расстояния, которое он помещает от пользователя. Визуальный угол основан на расстоянии между глазами пользователя и объектом и остается постоянным, а физический размер целевого объекта может измениться по мере изменения расстояния от пользователя. Чтобы определить необходимый физический размер объекта на основе расстояния от пользователя, попробуйте использовать визуальный калькулятор [угла, такой как.](https://elvers.us/perception/visualAngle/)

Ниже приведены рекомендации для минимального размера взаимодействующего содержимого.


### <a name="target-size-for-direct-hand-interaction"></a>Целевой размер для взаимодействия непосредственно с рукой

| расстояние; | Угол просмотра | Размер |
|---------|---------|---------|
| 45cm  | не меньше 2 ° | 1,6 x 1,6 cm |

![Целевой размер для взаимодействия непосредственно с рукой](images/TargetSizingNear.jpg)<br>
*Целевой размер для взаимодействия непосредственно с рукой*

<br>

### <a name="target-size-for-buttons"></a>Целевой размер для кнопок

При создании кнопок для прямого взаимодействия рекомендуется увеличить минимальный размер 3,2 x 3,2 cm, чтобы убедиться в наличии достаточного пространства для размещения значка и потенциального текста.

| расстояние; | Минимальный размер |
|---------|---------|
| 45cm  | 3,2 x 3,2 cm |

![Целевой размер для кнопок](images/TargetSizingButtons.png)<br>
*Целевой размер для кнопок*

<br>

### <a name="target-size-for-hand-ray-or-gaze-interaction"></a>Целевой размер для взаимодействия "рука" или "взгляд"
| расстояние; | Угол просмотра | Размер |
|---------|---------|---------|
| 2  | не меньше 1 ° | 3,5 x 3,5 cm |

![Целевой размер для взаимодействия "рука" или "взгляд"](images/TargetSizingFar.jpg)<br>
*Целевой размер для взаимодействия "рука" или "взгляд"*


<br>

---


## <a name="interactable-object-in-mrtk-mixed-reality-toolkit-for-unity"></a>Взаимодействующий объект в МРТК (набор средств для смешанной реальности) для Unity

В **[мртк](https://github.com/Microsoft/MixedRealityToolkit-Unity)** можно использовать [**взаимодействие**](https://github.com/microsoft/MixedRealityToolkit-Unity/tree/mrtk_release/Assets/MixedRealityToolkit.SDK/Features/UX/Interactable/Scripts) с скриптом, чтобы объекты отвечали на различные типы состояний взаимодействия. Он поддерживает различные типы тем, которые позволяют определять визуальные состояния, управляя свойствами объектов, такими как цвет, размер, материал и шейдер.

* [Элементом](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/README_Interactable.html)
* [Кнопка](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/README_Button.html)
* [Сцены с примерами взаимодействия руки](https://github.com/microsoft/MixedRealityToolkit-Unity/blob/mrtk_release/Documentation/README_HandInteractionExamples.md)

Стандартный шейдер Микседреалититулкит предоставляет различные параметры, такие как **освещение** , позволяющее создавать визуальные и звуковые подсказки.
* [Стандартный шейдер МРТК](https://github.com/microsoft/MixedRealityToolkit-Unity/blob/mrtk_development/Documentation/README_MRTKStandardShader.md)


<br>

---


## <a name="see-also"></a>См. также раздел

* [Курсоры](cursors.md)
* [Телекинез](point-and-commit.md)
* [Кнопка](button.md)
* [Активный объект](interactable-object.md)
* [Ограничивающая рамка и панель приложения](app-bar-and-bounding-box.md)
* [Оперирование](direct-manipulation.md)
* [Меню руки](hand-menu.md)
* [Быстрое меню](near-menu.md)
* [Коллекция объектов](object-collection.md)
* [Голосовая команда](voice-input.md)
* [Клавиатура](keyboard.md)
* [Подсказка](tooltip.md)
* [Планшет](slate.md)
* [Ползунок](slider.md)
* [Шейдер](shader.md)
* [Биллбординг и закрепление элемента в пространстве](billboarding-and-tag-along.md)
* [Индикация хода выполнения](progress.md)
* [Притяжение к поверхности](surface-magnetism.md)
