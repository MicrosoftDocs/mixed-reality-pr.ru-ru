---
title: Инстинктивное взаимодействие
description: Платформа Mixed Reality построена на принципах простого инстинктивного взаимодействия.
author: shengkait
ms.author: shentan
ms.date: 04/11/2019
ms.topic: article
ms.localizationpriority: high
keywords: Смешанная реальность, взгляд, нацеливание взглядом, взаимодействие, конструктор, HoloLens, MMR, мультимодальный
ms.openlocfilehash: 2f680a6682f848b6e6f12be599cc8a7fda35b1a6
ms.sourcegitcommit: 09599b4034be825e4536eeb9566968afd021d5f3
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 10/03/2020
ms.locfileid: "91699509"
---
# <a name="introducing-instinctual-interactions"></a>Знакомство с инстинктивным взаимодействием

![Манипулирование на большом расстоянии с помощью рук](images/04_InteractionFundamentals.png)

Платформа Mixed Reality (MR) построена на принципах простого инстинктивного взаимодействия. Мы сделали три шага, чтобы разработчики и конструкторы приложений могли предоставлять своим клиентам простые и понятные механизмы взаимодействия. 

Во-первых, мы объединили наши датчики и технологии ввода (включая отслеживание рук, отслеживание взгляда и естественный язык) в эффективные мультимодальные модели взаимодействия.  
Мы ведем исследования, создаем проекты и разрабатываем решения на базе мультимодальной платформы, а не на основе индивидуальных входных данных. Такой подход — ключ к созданию возможностей инстинктивного взаимодействия.

Во-вторых, мы учитываем, что многие разработчики ориентированы на несколько устройств HoloLens, таких как HoloLens 2 и HoloLens (1-го поколения) или HoloLens и виртуальная реальность.  
Поэтому мы разработали модели взаимодействия для работы на разных устройствах, даже если технология ввода зависит от устройства.  
Например, при удаленном взаимодействии гарнитуры Windows Immersive с контроллером 6DoF и при удаленном взаимодействии с HoloLens 2 используются одинаковые возможности и шаблоны. Это упрощает разработку приложений на нескольких устройствах и обеспечивает естественное взаимодействие с пользователем. 

Хотя мы признаем, что в смешанной реальности возможны тысячи эффективных, увлекательных и магических взаимодействий, мы обнаружили, что преднамеренное использование единой модели взаимодействия от начала до конца в приложении — это лучший способ обеспечить успешную работу пользователей и комфортное пользование. Поэтому в это руководство по взаимодействию мы включили три вещи.
* Специальные указания по трем основным моделям взаимодействия, а также по компонентам и шаблонам, необходимым для каждого.
* Дополнительное описание других преимуществ, которые предоставляет наша платформа.
* Общие инструкции по выбору подходящей модели взаимодействия для конкретного сценария разработки.

## <a name="multimodal-interaction-models"></a>Модели мультимодальных взаимодействий

Основываясь на наших исследованиях и отзывах клиентов, мы определили, что для реализации возможностей смешанной реальности подходят три основные модели взаимодействия. Во многих отношениях модель взаимодействия — это модель мышления пользователя для выполнения своего рабочего процесса. Каждая из этих моделей взаимодействия оптимизирована для ряда потребностей клиентов. При правильном применении каждая из них является простой, мощной и удобной в использовании. 

Диаграмма ниже представляет собой упрощенный обзор. Подробная информация об использовании каждой модели взаимодействия приведена ниже на страницах с изображениями и примерами кода. 

<br>
<table>
    <colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    </colgroup>
    <tr>
        <td><strong>Модель</strong></td>
        <td><strong>Примеры сценариев</strong></td>
        <td><strong>Совпадение</strong></td>
        <td><strong>Оборудование</strong></td>
    </tr>
    <tr>
        <td><a href="hands-and-tools.md">Руки и контроллеры движения</a></td>
        <td>Возможности трехмерного пространства, такие как пространственная структура и конструктор, манипулирование содержимым или симуляция.</td>
        <td>В сочетании с системой голосовой связи, отслеживанием взгляда или направления головы отлично подходит для новых пользователей. Низкий порог вхождения. Последовательное взаимодействие с пользователем для отслеживания рук и контроллеров 6DoF.</td>
        <td>HoloLens 2<br>Иммерсивные гарнитуры</td>
    </tr>
    <tr>
        <td><a href="hands-free.md">Режимы без использования рук</a></td>
        <td>Контекстуальные возможности, когда руки пользователя заняты, например, обучением на рабочем месте и обслуживанием.</td>
        <td>Требуется некоторое обучение. Если руки должны быть свободны, устройство обеспечивает удобное управление с помощью голоса и естественного языка.</td>
        <td>HoloLens 2<br>HoloLens (1-го поколения)<br>Иммерсивные гарнитуры</td>
    </tr>
    <tr>
        <td><a href="gaze-and-commit.md">Взгляд и фиксация</a></td>
        <td>Возможности перехода по ссылке, например 3D презентации, демоверсии.</td>
        <td>Требуется обучение на HMD, но не на мобильном. Лучшее для доступных контроллеров. Лучшее для HoloLens (1-го поколения)</td>
        <td>HoloLens 2<br>HoloLens (1-го поколения)<br>Иммерсивные гарнитуры<br>Mobile AR</td>
    </tr>
</table>
<br>

Чтобы избежать несоответствий в механизме взаимодействия с пользователем, на всех этапах следуйте инструкциям, касающимся одной и той же модели.

В следующих разделах рассматриваются этапы выбора и реализации одной из этих моделей взаимодействия.  
 
### <a name="by-the-end-of-this-page-you-will-understand-our-guidance-on"></a>К концу этой страницы вы будете основательно понимать следующие руководства.
 
* Выбор модели взаимодействия для вашего клиента
* Реализация модели взаимодействия
* Переход между моделями взаимодействия
* Следующие шаги конструктора


## <a name="choose-an-interaction-model-for-your-customer"></a>Выберите модель взаимодействия для вашего клиента

Как правило, разработчики и проектировщики решений продумывают типы взаимодействия, ориентируясь на потребности клиента. Чтобы поощрить такой подход к проектированию, мы рекомендуем следовать приведенным ниже инструкциям по выбору модели взаимодействия, оптимизированной для вашего клиента.

### <a name="why-follow-this-guidance"></a>Почему нужно следовать руководству?

* Наши модели взаимодействия проверяются по объективным и субъективным критериям, таким как физические и когнитивные трудозатраты, интуиция и обучаемость. 
* Так как есть множество способов взаимодействия, визуальные и звуковые возможности, а также поведение объекта отличаются в зависимости от конкретной модели.  
* Объединение частей нескольких моделей взаимодействия создает риск конкурирующих возможностей, таких как одновременное срабатывание телекинеза и курсора направления головы. Это может быть сложным для восприятия пользователей.

Ниже приведены несколько примеров того, как возможности и расширения функциональности оптимизируются для каждой модели взаимодействия. Мы часто видим, что у новых пользователей возникают похожие вопросы, например: " _Как я узнаю, что система работает_ , _как мне узнать, что я могу сделать_ , и _как узнать, поняла ли она мое действие?_ "

<br>

<table>
    <colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    </colgroup>
    <tr>
        <td><strong>Модель</strong></td>
        <td><strong>Как мне узнать, что она работает?</strong></td>
        <td><strong>Как мне узнать, что я могу сделать?</strong></td>
        <td><strong>Как мне узнать, что я только что сделал?</strong></td>
    </tr>
    <tr>
        <td><a href="hands-and-tools.md">Руки и контроллеры движения</a></td>
        <td>Я вижу виртуальную руку, возможность курсора для кончика пальца или телекинез либо лучи контроллера движений.</td>
        <td>Когда моя рука рядом с объектом, я вижу захватные маркеры или появление ограничивающего прямоугольника.</td>
        <td>Я слышу звуковые сигналы и вижу анимацию при захвате и выпуске.</td>
    </tr>
    <tr>
        <td><a href="gaze-and-commit.md">Направление головы и фиксация</a></td>
        <td>Я вижу курсор в центре моей видимой зоны.</td>
        <td>Курсор изменяется над определенными объектами.</td>
        <td>Я вижу визуальные подтверждения или слышу звуковые подтверждения при определенных действиях.</td>
    </tr>   
    <tr>
        <td><a href="hands-free.md">Без использования рук (Направление головы и остановка)</a></td>
        <td>Я вижу курсор в центре моей видимой зоны.</td>
        <td>Я вижу индикатор хода выполнения, когда останавливаюсь на интерактивном объекте.</td>
        <td>Я вижу визуальные подтверждения или слышу звуковые подтверждения при определенных действиях.</td>
    </tr>
    <tr>
        <td><a href="hands-free.md">Без использования рук (Голосовые команды)</a></td>
        <td>Я вижу индикатор прослушивания и заголовки, которые показывают, что слышала система.</td>
        <td>Я получаю голосовые приглашения и указания. Когда я говорю: "Что можно говорить?" Я вижу отзыв.</td>
        <td>Я вижу или слышу визуальные и звуковые подтверждения, когда даю команду, или пользовательский интерфейс устраняет неоднозначность, когда это необходимо.</a></td>
    </tr>
</table>

### <a name="below-are-questions-that-weve-found-help-teams-select-an-interaction-model"></a>Ниже приведены вопросы, которые, по нашему мнению, помогут командам выбрать модель взаимодействия.
 
1.  Вопрос.  Хотят ли мои пользователи хотят дотрагиваться до голограмм и выполнять точные голографические операции?<br><br>
Ответ.  Если это так, ознакомьтесь с моделью взаимодействия "Руки и контроллеры движений" для точного нацеливания и манипулирования.
 
2.  Вопрос.  Должны ли руки пользователей быть свободны, чтобы они могли выполнять определенные задачи в реальности?<br><br>
Ответ.  Если это так, обратите внимание на модель "Без использования рук", которая обеспечивает отличные возможности взаимодействия на основе направления взгляда и голосовых команд.
 
3.  Вопрос.  У моих пользователей есть время, чтобы освоить работу с моим приложением MR, или им нужно взаимодействие с минимальным периодом обучения?<br><br>
Ответ.  Рекомендуем использовать модель "Руки и контроллеры движений". Обучение работе с ней не занимает много времени, и она обеспечивает наиболее интуитивное взаимодействие, если пользователи могут задействовать руки.
 
4.  Вопрос.  Используют ли мои пользователи контроллеры движения для указывания и операций?<br><br>
Ответ.  Для модели "Руки и контроллеры движений" предоставляются полные инструкции, которые обеспечат успешную работу с контроллерами движения.
 
5.  Вопрос.  Используют ли мои пользователи контроллер специальных возможностей или обычный контроллер Bluetooth, такой как кликер?<br><br>
Ответ.  Мы рекомендуем использовать модель "Направление головы и подтверждение" для всех контроллеров, которые не отслеживаются. Она обеспечивает полное взаимодействие пользователя с системой с помощью простого механизма нацеливания и подтверждения. 
 
6.  Вопрос. Мои пользователи будут работать только с помощью "переходов" (например, в среде, похожей на слайд-шоу в трехмерном пространстве), не используя навигацию по многоуровневым элементам управления пользовательского интерфейса?<br><br>
Ответ.  Если пользователям не нужно контролировать большой объем пользовательского интерфейса, "Направление головы и фиксация" предлагают удобный для изучения вариант, когда им не нужно беспокоиться о нацеливании. 
 
7.  Вопрос.  Используют ли мои пользователи как HoloLens (1-го поколения), так и HoloLens 2 или иммерсивные гарнитуры (гарнитуры виртуальной реальности) Windows Mixed Reality?<br><br>
Ответ.  Так как "Направление головы и подтверждение" — это модель взаимодействия для HoloLens (1-го поколения), мы рекомендуем, чтобы разработчики, которые используют HoloLens (1-го поколения), применяли модель "Направление головы и фиксацию" для любых функций или режимов, которые пользователи будут применять на гарнитуре HoloLens (1-го поколения). Пожалуйста, обратитесь к следующему разделу ниже *Переходные модели взаимодействия* для получения подробных сведений о том, что нужно для комфортного пользования несколькими поколениями HoloLens.
 
8.  Вопрос. Есть ли различия между моделями для пользователей, которые обычно работают в большом пространстве или перемещаются между разными пространствами, и пользователей, которые, как правило, работают в одном пространстве?<br><br>
Ответ.  Любая из моделей взаимодействия подойдет этим пользователям.  

> [!NOTE]
> [В ближайшее время](../out-of-scope/news.md) появятся дополнительные руководства, касающиеся дизайна приложения.


## <a name="transitioning-interaction-models"></a>Переходные модели взаимодействия
Иногда нужно использовать более одной модели взаимодействия. Например, при создании приложения используется модель _Руки и контроллеры движений_ , но вам нужно применить режим "Без использования рук" для выездных техников.
Мы обнаружили, что при использовании нескольких моделей взаимодействия многим пользователям трудно переходить с одной на другую. Особенно это касается тех, кто только начинает работать с технологиями смешанной реальности.

> [!Note]
> Мы постоянно предоставляем разработчикам и дизайнерам дополнительные рекомендации относительно способов, сценариев и целей использования нескольких моделей взаимодействия MR.
 

## <a name="see-also"></a>См. также статью
* [Комфорт](comfort.md)
* [Взаимодействие на основе глаз](eye-gaze-interaction.md)
* [Отслеживание глаз в HoloLens 2](eye-tracking.md)
* [Взгляд и фиксация](gaze-and-commit.md)
* [Взгляд и остановка](gaze-and-dwell.md)
* [Руки: непосредственное манипулирование](direct-manipulation.md)
* [Руки: жесты](gaze-and-commit.md#composite-gestures)
* [Руки: наведение и фиксация](point-and-commit.md)
* [Инстинктивное взаимодействие](interaction-fundamentals.md)
* [Контроллеры движения](motion-controllers.md)
* [Пространственное сопоставление](spatial-mapping.md)
* [Проектирование пространственного звука](spatial-sound-design.md)
* [Голосовой ввод](voice-input.md)


