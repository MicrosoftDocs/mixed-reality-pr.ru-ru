---
title: 4. Настройка интерактивной сцены
description: Часть 4 (из 6) серии руководств по созданию приложения для игры в шахматы с помощью Unreal Engine 4 и подключаемого модуля Mixed Reality UX Tools
author: hferrone
ms.author: v-hferrone
ms.date: 11/18/2020
ms.topic: article
ms.localizationpriority: high
keywords: Unreal, Unreal Engine 4, UE4, HoloLens, HoloLens 2, смешанная реальность, учебник, начало работы, MRTK, UXT, UX Tools, документация, гарнитура смешанной реальности, гарнитура Windows Mixed Reality, гарнитура виртуальной реальности
ms.openlocfilehash: c26f5579aad29624c9a8f374caa4799423d0637e
ms.sourcegitcommit: 04927427226928bd9178da0049d4cef626a6b0bf
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/21/2021
ms.locfileid: "98635444"
---
# <a name="4-making-your-scene-interactive"></a>4. Настройка интерактивной сцены

При работе с предыдущим руководством мы добавили элементы ARSession, Pawn и Game Mode, чтобы настроить наше шахматное приложение для смешанной реальности. Этот раздел посвящен использованию подключаемого модуля [средств UX из набора средств для смешанной реальности](https://github.com/microsoft/MixedReality-UXTools-Unreal), который имеет открытый исходный код и содержит средства для придания сцене интерактивности. Когда вы завершите работу с этим разделом, шахматные фигуры будут реагировать на действия пользователя.

## <a name="objectives"></a>Задачи

* Установка подключаемого модуля Mixed Reality UX Tools из GitHub
* Добавление субъектов взаимодействия с руками.
* Создание и добавление манипуляторов для физического взаимодействия с объектами в сцене.
* Применение имитации ввода для проверки проекта.

## <a name="downloading-the-mixed-reality-ux-tools-plugin"></a>Скачивание подключаемого модуля Mixed Reality UX Tools
Прежде чем приступить к работе с пользовательским вводом, необходимо добавить подключаемый модуль в проект.

1. На [странице выпусков](https://github.com/microsoft/MixedReality-UXTools-Unreal/releases) Mixed Reality UX Tools на GitHub перейдите к выпуску средств пользовательского интерфейса для Unreal версии 0.10.0 и скачайте файл **UXTools.0.10.0.zip**. Распакуйте файл.

2.  В корневой папке проекта создайте папку с именем **Plugins**. Скопируйте распакованный подключаемый модуль UXTools в эту папку и перезапустите редактор Unreal.

![Создание папки для подключаемых модулей в проекте](images/unreal-uxt/4-plugins.PNG)

3.  Подключаемый модуль UX Tools содержит папку Content с вложенными папками для компонентов, в том числе **кнопок**, **функции имитации ввода** и **указателей**, а также папку с классами C++ с дополнительным кодом.  

> [!NOTE]
> Если в обозревателе контента (**Content Browser**) не виден раздел **UXTools Content** (Контент UXTools), выберите **View Options > Show Plugin Content** (Параметры просмотра > Показывать содержимое подключаемых модулей).

![Отображение содержимого подключаемого модуля](images/unreal-uxt/4-showplugincontent.PNG)

Дополнительную документацию по подключаемым модулям можно найти в [репозитории](https://aka.ms/uxt-unreal) Mixed Reality UX Tools на GitHub.

Теперь, когда подключаемый модуль установлен, можно приступить к работе с содержащимися в нем средствами. Начнем с субъектов взаимодействия с рукой.

## <a name="spawning-hand-interaction-actors"></a>Порождение субъектов взаимодействия с рукой

Взаимодействие элементов пользовательского интерфейса с руками пользователя реализуется с помощью субъектов взаимодействия с рукой, которые создают и перемещают указатели, а также визуальные элементы для ближних и дальних взаимодействий.
- Для *ближних взаимодействий* пользователь сжимает элементы между большим и указательным пальцами или касается элементов кончиком пальца.
- Для *дальних взаимодействий* пользователь наводит на элемент луч из виртуальной руки, а затем соединяет большой и указательный пальцы.

Когда мы добавим субъект взаимодействия с рукой к элементу **MRPawn**, произойдет следующее:
- На кончиках указательных пальцев при взаимодействии с объектом Pawn будет отображаться курсор.
- Появятся события жестового ручного ввода, которыми можно будет манипулировать через объект Pawn.
- Появятся события ввода с дальним взаимодействием при помощи лучей телекинеза, исходящих из запястий виртуальных рук.

Прежде чем продолжать, изучите [документацию](https://microsoft.github.io/MixedReality-UXTools-Unreal/Docs/HandInteraction.html) по взаимодействию с помощью рук.

Когда будете готовы, откройте схему **MRPawn** и перейдите к разделу **Event Graph** (Граф событий).

1. Перетащите закрепление выполнения из узла **Event BeginPlay** и отпустите его, чтобы создать еще один узел.
    * Выберите **Spawn Actor from Class** (Породить субъект из класса), щелкните стрелку раскрывающегося списка справа от закрепления **Class** (Класс) и найдите узел **Uxt Hand Interaction Actor** (Субъект взаимодействия с рукой Uxt).  

2. Создайте второй узел **Uxt Hand Interaction Actor** (Субъект взаимодействия с рукой), но на этот раз задайте для параметра **Hand** (Рука) значение **Right** (Правая). В начале события для каждой руки будет порожден субъект взаимодействия с рукой Uxt.

Теперь поле **Event Graph** (Граф событий) должно выглядеть так, как показано на приведенном ниже снимке экрана.

![Порождение субъектов взаимодействия с рукой](images/unreal-uxt/4-spawnactor.PNG)

Для обоих субъектов взаимодействия с рукой Uxt необходимо задать владельцев и координаты начального преобразования. В этом случае начальное преобразование не играет роли, так как с помощью UX Tools субъекты взаимодействия с рукой будут перемещены на виртуальные руки, как только последние станут видимыми. Но функции `SpawnActor` требуется входной параметр Transform, чтобы не произошла ошибка компиляции, поэтому зададим значения по умолчанию.

1. Перетащите закрепление одного из элементов **Spawn Transform** (Порождение преобразования) и отпустите его, чтобы создать еще один узел.
    * Найдите узел **Make Transform** (Создание преобразования) и перетащите его закрепление **Return Value** (Возвращаемое значение) на узел **Spawn Transform** (Порождение преобразования) другой руки, чтобы соединить оба узла **SpawnActor**.

2.  Щелкните **стрелку вниз** в нижней части обоих узлов **SpawnActor**, чтобы открыть закрепление **Owner** (Владелец).    
    * Перетащите закрепление одного из элементов **Owner** (Владелец) и отпустите его, чтобы разместить новый узел.
    * Выполните поиск по слову **self** и выберите переменную **Get a reference to self** (Получить ссылку на себя).
    * Создайте связь между узлом ссылки на объект **Self** и закреплением **Owner** (Владелец) другого субъекта взаимодействия с рукой.
3. Наконец, установите флажок **Show Near Cursor on Grab Targets** (Показывать курсор при приближению к целям захвата) для обоих субъектов взаимодействия с рукой. Курсор должен отображаться на цели захвата при приближении указательного пальца, чтобы вы могли видеть, где находится ваш палец относительно цели.
    * **Скомпилируйте**, **сохраните** схему и вернитесь к главному окну.

Соединения должны соответствовать приведенному ниже снимку экрана, но вы можете изменить расположение узлов, чтобы сделать схему более удобочитаемой.

![Полная конфигурация субъектов взаимодействия с рукой](images/unreal-uxt/4-fingerptrs.PNG)

Дополнительные сведения о субъектах взаимодействия с рукой см. в [документации по UX Tools](https://microsoft.github.io/MixedReality-UXTools-Unreal/Docs/HandInteraction.html).

Теперь с помощью виртуальных рук в проекте можно выбирать объекты, но пока еще нельзя манипулировать ими. Последнее, что необходимо сделать, прежде чем тестировать приложение — добавить к субъектам в сцене компоненты Manipulator, или манипуляторы.

## <a name="attaching-manipulators"></a>Добавление манипуляторов

Манипулятор (Manipulator) — это компонент, который реагирует на жестовый ручной ввод. Его можно захватывать, вращать и перемещать в пространстве. Если применить преобразование манипулятора к преобразованию субъекта, это позволит непосредственно манипулировать субъектом.

1. На панели **Components** (Компоненты) откройте схему **Board**, нажмите кнопку **Add Component** (Добавить компонент) и найдите узел **Uxt Generic Manipulator** (Универсальный манипулятор Uxt).

![Добавление универсального манипулятора](images/unreal-uxt/4-addmanip.PNG)

2. На панели **Details** (Сведения) разверните раздел **Generic Manipulator** (Универсальный манипулятор). Здесь можно настроить манипулирование одной или двумя руками, режим вращения и сглаживание. Вы можете выбрать здесь любой удобный режим, а затем **скомпилировать** и **сохранить** схему Board.

![Настройка режима](images/unreal-uxt/4-setrotmode.PNG)

3. Повторите описанные выше действия для субъекта **WhiteKing**.

Дополнительные сведения о компонентах Manipulator, которые входят в состав подключаемого модуля Mixed Reality UX Tools, см. в [документации](https://microsoft.github.io/MixedReality-UXTools-Unreal/Docs/Manipulator.html).

## <a name="testing-the-scene"></a>Тестирование сцены

Теперь все готово к тестированию приложения с новыми виртуальными руками и пользовательским вводом. Нажмите кнопку **Play** (Воспроизвести) в главном окне. Отобразятся две сетчатые руки и два луча телекинеза, выходящие из ладоней этих рук. Управлять этими руками и соответствующими взаимодействиями вы можете так:
- Удерживайте нажатой **левую клавишу ALT** для управления **левой рукой** и **левую клавишу SHIFT** для управления **правой рукой**.
- Перемещайте мышь для перемещения руки и прокручивайте **колесико мыши** для перемещения руки **вперед** и **назад**.
- Нажмите левую кнопку мыши, чтобы **сжать** объект между указательным и большим пальцами, и среднюю кнопку, чтобы **коснуться** объекта.

> [!NOTE]
> Имитация ввода может не работать, если к вашему компьютеру подключено несколько гарнитур. Если у вас возникли проблемы, попробуйте отключить другие гарнитуры.

![Симуляция рук в окне просмотра](images/unreal-uxt/4-handsim.PNG)

Попробуйте теперь с помощью этих виртуальных рук поднять белого короля с доски, переместить его и поставить на другое место. Потренируйтесь в выполнении ближнего и дальнего взаимодействия. Вы заметите, что при приближении рук к доске и (или) к королю на расстоянии прямого захвата луч телекинеза заменяется курсором в виде пальца на кончике указательного пальца.

Дополнительные сведения о функции имитации рук, которая входит в состав подключаемого модуль средств UX из MRTK, см. в [документации](https://microsoft.github.io/MixedReality-UXTools-Unreal/Docs/InputSimulation.html).

Теперь, когда ваши виртуальные руки научились взаимодействовать с объектами, можно переходить к следующему разделу, в котором мы добавим пользовательские интерфейсы и события.

[Следующий раздел: 5. Добавление кнопки и сброс расположений фрагментов](unreal-uxt-ch5.md)
