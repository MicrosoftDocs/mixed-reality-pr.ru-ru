---
title: Отслеживание рук в Unreal
description: Узнайте, как использовать входные данные отслеживания, а именно сетки и анимацию Live Link в нереальных приложениях смешанной реальности.
author: hferrone
ms.author: v-hferrone
ms.date: 06/10/2020
ms.topic: article
keywords: Windows Mixed Reality, отслеживание, неreal, нереалное ядро 4, UE4, HoloLens, HoloLens 2, Смешанная реальность, разработка, функции, документация, руководства, голограммы, Разработка игр, гарнитура смешанной реальности, гарнитура Windows Mixed Reality, гарнитура виртуальной реальности
ms.openlocfilehash: 1888258321af978ca52623008193e6dae94833a8
ms.sourcegitcommit: d3a3b4f13b3728cfdd4d43035c806c0791d3f2fe
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/20/2021
ms.locfileid: "98581111"
---
# <a name="hand-tracking-in-unreal"></a>Отслеживание рук в Unreal

Система отслеживания руки в качестве входных данных использует Палмс и пальцы человека. Данные по положению и повороту каждого пальца доступны все жесты Palm и руки. Начиная с нереального 4,26, отслеживание выполняется на основе нереального подключаемого модуля Хеадмаунтеддисплай и использует общий API на всех платформах и устройствах XR. Функции одинаковы для систем Windows Mixed Reality и Опенкср.

## <a name="hand-pose"></a>Рука

Рука руки позволяет относить и использовать руки и пальцы пользователей в качестве входных данных, к которым можно получить доступ как в чертежах, так и в C++. Нереалный API отправляет данные в виде системы координат с тактами, синхронизированными с нереальным механизмом.

![Схема руки](../native/images/hand-skeleton.png)

[!INCLUDE[](includes/tabs-tracking-hand-pose.md)]

## <a name="hand-live-link-animation"></a>Анимация прямой связи

Руки, доступные для анимации, используют [подключаемый модуль динамической компоновки](https://docs.unrealengine.com/Engine/Animation/LiveLinkPlugin/index.html).

Если включены подключаемые модули Windows Mixed Reality и Live links:
1. Выберите **окно > активная ссылка** , чтобы открыть окно редактора динамической связи.
2. Выбор **источника** и включение **источника отслеживания Windows Mixed Reality**

![Источник прямой связи](images/unreal/live-link-source.png)

После включения источника и открытия ресурса анимации раскройте раздел " **анимация** " на вкладке " **Предварительный просмотр** ". Дополнительные параметры см. здесь.

![Динамическая анимация ссылки](images/unreal/live-link-animation.png)

Иерархия анимации руки такая же, как и в `EWMRHandKeypoint` . Анимацию можно перенацелить с помощью **виндовсмикседреалитихандтраккингливелинкремапассет**:

![Анимация прямой связи 2](images/unreal/live-link-animation2.png)

Он также может быть подклассом в редакторе:

![Сопоставление активных ссылок](images/unreal/live-link-remap.png)

## <a name="hand-mesh"></a>Сетка руки

### <a name="hand-mesh-as-a-tracked-geometry"></a>Сетка "рука" в виде отслеживающей геометрии

> [!IMPORTANT]
> Для получения сеток в качестве отслеживаемой геометрии в Опенкср необходимо вызвать **set use сетчатая сетка** с **включенной геометрией отслеживания**.

Чтобы включить этот режим, следует вызвать **set use сетчатая сетка** с **включенной геометрией отслеживания**:

![Схема начала воспроизведения подключена к параметру использовать сетку данных с включенным режимом геометрического отслеживания](images/unreal-hand-tracking-img-08.png)

> [!NOTE]
> Одновременное включение обоих режимов невозможно. Если включить один, то другой автоматически отключается.

### <a name="accessing-hand-mesh-data"></a>Доступ к данным сетки

![Сетка руки](images/unreal/hand-mesh.png)

Прежде чем можно будет получить доступ к данным сетки данных, необходимо:
- Выберите свой ресурс **арсессионконфиг** , разверните параметры **AR Settings-> мирового сопоставления** и установите флажок **создать данные сетки из отслеживающей геометрии**.

Ниже приведены параметры сетки по умолчанию.

1.  Использование данных сетки для перекрытия
2.  Создать конфликт для данных сетки
3.  Создать сетку навигации для данных сетки
4.  Отображение данных сетки в каркасе — параметр отладки, показывающий созданную сетку

Эти значения параметров используются в качестве сетки пространственного сопоставления и по умолчанию для сетки. Их можно изменить в любой момент в проекте или коде для любой сетки.

### <a name="c-api-reference"></a>Справочник по API C++
Используется `EEARObjectClassification` для поиска значений сетки в объектах, доступных для наблюдения.
```cpp
enum class EARObjectClassification : uint8
{
    // Other types
    HandMesh,
};
```

Следующие делегаты вызываются, когда система обнаруживает любой отслеживающий объект, включая сетку типа "рука".

```cpp
class FARSupportInterface
{
    public:
    // Other params
    DECLARE_AR_SI_DELEGATE_FUNCS(OnTrackableAdded)
    DECLARE_AR_SI_DELEGATE_FUNCS(OnTrackableUpdated)
    DECLARE_AR_SI_DELEGATE_FUNCS(OnTrackableRemoved)
};
```

Убедитесь, что обработчики делегатов следуют сигнатуре функции ниже:

```cpp
void UARHandMeshComponent::OnTrackableAdded(UARTrackedGeometry* Added)
```

Доступ к данным сетки можно получить с помощью  `UARTrackedGeometry::GetUnderlyingMesh` :

```cpp
UMRMeshComponent* UARTrackedGeometry::GetUnderlyingMesh()
```

### <a name="blueprint-api-reference"></a>Справочник по API-интерфейсам схем

Для работы с сетчатыми сетками в схемах:
1. Добавление компонента **артраккабленотифи** в проект схемы

![Уведомление Артраккабле](images/unreal/ar-trackable-notify.png)

2. Перейдите на панель **сведений** и разверните раздел **события** .

![Артраккабле уведомление 2](images/unreal/ar-trackable-notify2.png)

3. Перезаписать для добавления, обновления или удаления отслеживаний геометрии со следующими узлами в графе событий:

![Уведомление Артраккабле](images/unreal/on-artrackable-notify.png)

### <a name="hand-mesh-visualization-in-openxr"></a>Визуализация сетки руки в Опенкср

Чтобы визуализировать сетку, рекомендуется использовать подключаемый модуль Ксрвисуализатион в ситуации с [подключаемым модулем Microsoft опенкср](https://github.com/microsoft/Microsoft-OpenXR-Unreal). 

Затем в редакторе схем следует использовать функцию **set use сетчатой** функции из [подключаемого модуля Microsoft опенкср](https://github.com/microsoft/Microsoft-OpenXR-Unreal) с **включенной ксрвисуализатион** в качестве параметра:

![Схема начала воспроизведения подключена к параметру использовать сетку руки с включенным режимом ксрвисуализатион](images/unreal-hand-tracking-img-05.png)

Для управления процессом отрисовки следует использовать **контроллер движения Render** из ксрвисуализатион:

![Схема получения функции данных контроллера движения, подключенной к функции контроллера движения прорисовки](images/unreal-hand-tracking-img-06.png)

Получаются такие результаты:

![Изображение цифрового руки, наложенное на реальную человеческий рукой](images/unreal-hand-tracking-img-07.png) 

Если вам нужно нечто более сложное, например рисовать сетку руки с помощью пользовательского шейдера, необходимо получить сетки в виде отслеживающей геометрии. 

## <a name="hand-rays"></a>Лучи рук

Функция руки работает для замкнутых взаимодействий, таких как извлечение объектов или нажатие кнопок. Однако иногда требуется работать с голограммами, которые находятся далеко от пользователей. Это можно сделать с помощью луча, которые можно использовать в качестве указывающих устройств как в C++, так и в чертежах. Вы можете нарисовать луч от руки до дальнего времени и с помощью некоторой помощи от нереальной трассировки лучей выбрать голограмму, которая в противном случае будет недоступна. 

> [!IMPORTANT]
> Поскольку все результаты всех функций изменяются каждый кадр, все они становятся вызываемыми. Дополнительные сведения о чистом и нечистом или вызываемых функциях см. в статье GUID пользователя в [функциях](https://docs.unrealengine.com/Engine/Blueprints/UserGuide/Functions/index.html#purevs.impure).

[!INCLUDE[](includes/tabs-tracking-hand-ray.md)]

## <a name="gestures"></a>Жесты

HoloLens 2 отслеживает пространственные жесты, что означает, что эти жесты можно записать в качестве входных данных. Отслеживание жестов основано на модели подписки. Используйте функцию "Настройка жестов", чтобы сообщить устройству, какие жесты необходимо отслеживанию.  Дополнительные сведения о жестах можно найти в документе [об использовании HoloLens 2](/hololens/hololens2-basic-usage) .

[!INCLUDE[](includes/tabs-tracking-gestures.md)]

## <a name="next-development-checkpoint"></a>Следующий этап разработки

Если вы следуете изложенным нами инструкциям по разработке для Unreal, вы как раз прошли половину в изучении основных стандартных блоков MRTK. Отсюда вы можете перейти к следующему стандартному блоку:

> [!div class="nextstepaction"]
> [Локальные пространственные привязки](unreal-spatial-anchors.md)

Или перейдите к возможностям и API платформы смешанной реальности:

> [!div class="nextstepaction"]
> [Камера HoloLens](unreal-hololens-camera.md)

Вы можете в любой момент вернуться к [этапам разработки для Unreal](unreal-development-overview.md#2-core-building-blocks).