---
title: Взгляните на входные данные в нереальном режиме
description: узнайте, как настроить и использовать ввод с помощью взгляда с отслеживанием глаз и ориентацией на голове для HoloLens приложений в нереальном режиме.
author: hferrone
ms.author: jacksonf
ms.date: 12/9/2020
ms.topic: article
keywords: Windows Mixed Reality, голограммы, HoloLens 2, отслеживание глаз, входные данные взгляда, подключенный головной дисплей, нереалный механизм, гарнитура смешанной реальности, гарнитура Windows Mixed reality, головной офис виртуальной реальности
ms.openlocfilehash: e423086e293629e3dfadb49b52a376c0b93f5e465328b93f47c2f1e3e0790b63
ms.sourcegitcommit: a1c086aa83d381129e62f9d8942f0fc889ffcab0
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 08/05/2021
ms.locfileid: "115200680"
---
# <a name="gaze-input"></a>Входные данные взгляда

Взгляните на ввод в приложениях смешанной реальности, чтобы узнать, что пользователи видят. Когда камеры отслеживания взгляда на устройстве сопоставляются с лучами в нереальном пространстве, данные о пользователе становятся доступными. Взгляд можно использовать как в чертежах, так и в C++, и является основным компонентом для таких ядер, как взаимодействие объектов, Поиск и управление камерой.

## <a name="enabling-eye-tracking"></a>Включение отслеживания взгляда

- в **Project Параметры > HoloLens** включите функцию ввода с помощью средства **входа** .

![снимок экрана с возможностями параметра проекта HoloLens с выделенными входными данными](images/unreal-gaze-img-01.png)

- Создание нового субъекта и его добавление в сцену

> [!NOTE]
> HoloLens отслеживание взгляда в нереальном времени имеет один луч для обоих глаз. Отслеживание стереоскопик, для которого требуется два луча, не поддерживается.

## <a name="using-eye-tracking"></a>Использование функции отслеживания взгляда

Сначала убедитесь, что устройство поддерживает отслеживание взгляда с помощью функции **исэйетраккерконнектед** .  Если функция возвращает значение true, вызовите **жетгазедата** , чтобы найти, где глаза пользователя просматриваются в текущем кадре:

![Схема подключенной функции отслеживания взгляда](images/unreal-gaze-img-02.png)

> [!NOTE]
> Точка с фиксацией и значение достоверности недоступны на HoloLens.

Используйте источник и направление взгляда в трассировке строки, чтобы точно определить, где находятся ваши пользователи.  Значение взгляда является вектором, начинающимся с источника взгляда и заканчивая началом координат, а также направлением взгляда, умноженным на расстояние трассировки строки:

![Схема функции получения данных об взгляде](images/unreal-gaze-img-03.png)

## <a name="getting-head-orientation"></a>Получение ориентации головного экрана

Также можно использовать поворот головного дисплея (ХМД) для представления направления заголовка пользователя. Вы можете получить направление заголовка пользователей, не включив функцию ввода с клавиатуры, но не будете получать сведения об отслеживании взгляда.  Добавьте ссылку на проект в качестве контекста мира, чтобы получить правильные выходные данные:

> [!NOTE]
> Получение данных ХМД доступно только в нереальных 4,26 и более.

![Схема функции Get Хмддата](images/unreal-gaze-img-04.png)

## <a name="using-c"></a>Использование C++

- В файле **Build. CS** вашей игры добавьте **Эйетраккер** в список **публикдепенденцимодуленамес** :

```cpp
PublicDependencyModuleNames.AddRange(
    new string[] {
        "Core",
        "CoreUObject",
        "Engine",
        "InputCore",
        "EyeTracker"
});
```

- В **файле или новом классе c++** создайте новый субъект c++ с именем **эйетраккер**
    - Visual Studio решение откроет новый класс эйетраккер. Выполните сборку и запустите, чтобы открыть нереальную игру с новым субъектом Эйетраккер.  Выполните поиск строки "Эйетраккер" в окне " **место субъектов** " и перетащите класс в окно игры, чтобы добавить его в проект:

![Снимок экрана субъекта с открытым окном субъекта](images/unreal-gaze-img-06.png)

- В **эйетраккер. cpp** добавьте включения для **эйетраккерфунктионлибрари** и **дравдебугхелперс**:

```cpp
#include "EyeTrackerFunctionLibrary.h"
#include "DrawDebugHelpers.h"
```

Убедитесь, что устройство поддерживает отслеживание взгляда с помощью **уэйетраккерфунктионлибрари:: исэйетраккерконнектед** , прежде чем пытаться получить данные о взгляде.  Если отслеживание взгляда поддерживается, найдите начало и конец луча для трассировки строки из **уэйетраккерфунктионлибрари:: жетгазедата**. После этого можно создать вектор взгляда и передать его содержимое в **линетрацесинглебичаннел** для отладки любых результатов попадания луча:

```cpp
void AEyeTracker::Tick(float DeltaTime)
{
    Super::Tick(DeltaTime);

    if(UEyeTrackerFunctionLibrary::IsEyeTrackerConnected())
    {
        FEyeTrackerGazeData GazeData;
        if(UEyeTrackerFunctionLibrary::GetGazeData(GazeData))
        {
            FVector Start = GazeData.GazeOrigin;
            FVector End = GazeData.GazeOrigin + GazeData.GazeDirection * 100;

            FHitResult Hit Result;
            if (GWorld->LineTraceSingleByChannel(HitResult, Start, End, ECollisionChannel::ECC_Visiblity))
            {
                DrawDebugCoordinateSystem(GWorld, HitResult.Location, FQuat::Identity.Rotator(), 10);
            }
        }
    }
}
```

## <a name="next-development-checkpoint"></a>Следующий этап разработки

Если вы следуете изложенным нами инструкциям по разработке для Unreal, вы как раз прошли половину в изучении основных стандартных блоков MRTK. Отсюда вы можете перейти к следующему стандартному блоку:

> [!div class="nextstepaction"]
> [Отслеживание рук](unreal-hand-tracking.md)

Или перейдите к возможностям и API платформы смешанной реальности:

> [!div class="nextstepaction"]
> [Камера HoloLens](unreal-hololens-camera.md)

Вы можете в любой момент вернуться к [этапам разработки для Unreal](unreal-development-overview.md#2-core-building-blocks).

## <a name="see-also"></a>См. также статью
* [Калибровка](/hololens/hololens-calibration)
* [Комфорт](../../design/comfort.md)
* [Взгляд и фиксация](../../design/gaze-and-commit.md)
* [Голосовой ввод](../../out-of-scope/voice-design.md)