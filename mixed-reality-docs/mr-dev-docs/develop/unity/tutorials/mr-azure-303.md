---
title: MR и Azure 303 — понимание естественного языка (LUIS)
description: Пройдите этот курс, чтобы узнать, как реализовать службу Azure Language Understanding Intelligence (LUIS) в приложении смешанной реальности.
author: drneil
ms.author: jemccull
ms.date: 07/04/2018
ms.topic: article
keywords: Azure, Mixed Reality, Academy, Unity, учебник, API, Служба анализа языка, Luis, hololens, иммерсивное, VR
ms.openlocfilehash: 8477f326de55c11f1c4d17d808a815f01366be0d
ms.sourcegitcommit: 09599b4034be825e4536eeb9566968afd021d5f3
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 10/03/2020
ms.locfileid: "91693589"
---
# <a name="mr-and-azure-303-natural-language-understanding-luis"></a>MR и Azure 303: понимание естественного языка (LUIS)

<br>

>[!NOTE]
>Руководства Mixed Reality Academy были разработаны для иммерсивных гарнитур HoloLens (1-го поколения) и иммерсивных гарнитур Mixed Reality.  Поэтому мы считаем, что важно оставить эти руководства для разработчиков, которые ищут рекомендации по разработке для этих устройств.  Данные руководства **_не_** будут обновляться с учетом последних наборов инструментов или возможностей взаимодействия для HoloLens 2.  Они будут сохранены для работы на поддерживаемых устройствах. Появится новая серия руководств, которые будут опубликованы в будущем, где будет показано, как разрабатывать данные для HoloLens 2.  Это уведомление будет обновлено ссылкой на эти учебники при их публикации.

<br>

В этом курсе вы узнаете, как интегрировать Language Understanding в приложение смешанной реальности с помощью Cognitive Services Azure с API распознавания речи.

![Результат лаборатории](images/AzureLabs-Lab3-000.png)

*Language Understanding (Luis)* — это Microsoft Azure служба, которая предоставляет приложениям возможность принимать значения из вводимых пользователем данных, например, путем извлечения того, что может потребоваться пользователю, в отдельных словах. Это достигается благодаря машинному обучению, которое понимает и изучает входные данные, а затем может ответить на подробные и релевантные сведения. Дополнительные сведения см. на [странице Language Understanding Azure (Luis)](https://azure.microsoft.com/services/cognitive-services/language-understanding-intelligent-service/).

Прополнив этот курс, вы получите иммерсивное приложение для наушников, которое сможет сделать следующее:

1.  Запись речевого ввода пользователя с помощью микрофона, подключенного к иммерсивное гарнитуре. 
2.  Отправка захваченной диктовки *Language Understanding Intelligent Service Azure* ( *Luis* ). 
3.  LUIS извлечение значения из сведений об отправке, которые будут проанализированы, и попытаться определить цель запроса пользователя.

Разработка будет включать в себя создание приложения, в котором пользователь сможет использовать голоса и (или) Взгляните, чтобы изменить размер и цвет объектов в сцене. Использование контроллеров движения не будет охвачено.

В приложении вы будете выполнять интеграцию результатов с вашей структурой. Этот курс предназначен для изучения того, как интегрировать службу Azure с проектом Unity. Это ваша задача использовать знания, полученные из этого курса, для улучшения приложения смешанной реальности.

Будьте готовы обучить LUIS несколько раз, как описано в [главе 12](#chapter-12--improving-your-luis-service). Вы получите лучшие результаты, которые больше LUIS обучены.

## <a name="device-support"></a>Поддержка устройств

<table>
<tr>
<th>Курс</th><th style="width:150px"> <a href="../../../hololens-hardware-details.md">HoloLens</a></th><th style="width:150px"> <a href="../../../discover/immersive-headset-hardware-details.md">Иммерсивные гарнитуры</a></th>
</tr><tr>
<td>MR и Azure 303: понимание естественного языка (LUIS)</td><td style="text-align: center;"> ✔️</td><td style="text-align: center;"> ✔️</td>
</tr>
</table>

> [!NOTE]
> Хотя этот курс в основном ориентирован на гарнитуры Windows Mixed Reality (VR), вы также можете применить сведения, которые вы узнаете в этом курсе, к Microsoft HoloLens. Как вы пройдете вместе с курсом, вы увидите примечания о любых изменениях, которые могут потребоваться для поддержки HoloLens. При использовании HoloLens вы можете заметить некоторые эхо во время записи голоса.

## <a name="prerequisites"></a>Предварительные требования

> [!NOTE]
> Этот учебник предназначен для разработчиков, имеющих базовый опыт работы с Unity и C#. Также имейте в виду, что предварительные требования и письменные инструкции в этом документе отражают, что проверялось и проверено во время написания статьи (Май 2018). Вы можете использовать новейшее программное обеспечение, как указано в статье [Установка средств](../../install-the-tools.md) , но не следует предполагать, что информация в этом курсе будет полностью соответствовать тому, что вы найдете в более новом программном обеспечении, чем показано ниже.

Для этого курса рекомендуется следующее оборудование и программное обеспечение:

- ПК для разработки, [совместимый с Windows Mixed Reality](https://support.microsoft.com/help/4039260/windows-10-mixed-reality-pc-hardware-guidelines) для разработки головных телефонов (VR)
- [Windows 10 для дизайнеров с обновлением (или более поздней версии) с включенным режимом разработчика](../../install-the-tools.md)
- [Последний пакет SDK для Windows 10](../../install-the-tools.md)
- [Unity 2017,4](../../install-the-tools.md)
- [Visual Studio 2017](../../install-the-tools.md)
- Высокодоступная [гарнитура Windows Mixed Reality (VR)](../../../discover/immersive-headset-hardware-details.md) или [Microsoft HoloLens](../../../hololens-hardware-details.md) с включенным режимом разработчика
- Набор наушников со встроенным микрофоном (если у гарнитуры нет встроенного MIC и динамиков);
- Доступ к Интернету для установки Azure и извлечения LUIS

## <a name="before-you-start"></a>Перед началом работы

1.  Чтобы избежать проблем при создании этого проекта, настоятельно рекомендуется создать проект, упомянутый в этом руководстве, в корневой или ближайшем к корневой папке (длинные пути к папкам могут вызвать проблемы во время сборки). 
2.  Чтобы разрешить компьютеру Включить диктовку, перейдите в раздел **Параметры Windows > конфиденциальность > речи, ввод рукописных данных & ввода** и нажмите кнопку **включить речевые службы и ввести предложения** .
3.  Код в этом учебнике позволит вам записывать данные из набора устройств на основе **микрофона по умолчанию** на компьютере. Убедитесь, что в качестве микрофона по умолчанию выбрано устройство, которое вы хотите использовать для записи голоса.
4.  Если у гарнитуры есть встроенный микрофон, убедитесь, что параметр *"при износе гарнитуры, переключиться на микрофон гарнитуры"* включен в параметрах *портала смешанной реальности* .

    ![Настройка иммерсивного головного телефона](images/AzureLabs-Lab3-00.png)

## <a name="chapter-1--setup-azure-portal"></a>Глава 1 — Настройка портала Azure

Чтобы использовать службу *Language Understanding* в Azure, необходимо настроить экземпляр службы, чтобы сделать ее доступной для приложения.

1.  Войдите на [портал Azure](https://portal.azure.com).

    > [!NOTE]
    > Если у вас еще нет учетной записи Azure, необходимо создать ее. Если вы используете этот учебник в учебной или лабораторной ситуации, обратитесь к своему преподавателю или к одной из прокторс, чтобы получить помощь в настройке новой учетной записи.

2.  Войдя в систему, щелкните New ( **создать** ) в левом верхнем углу, найдите *Language Understanding* и нажмите клавишу **Ввод** . 

    ![Создание ресурсов LUIS](images/AzureLabs-Lab3-01.png)

    > [!NOTE]
    > Слово **New** может быть заменено на **создать ресурс** в новых порталах.
 
3.  На новой странице справа будет представлено описание службы Language Understanding. В нижнем левом углу этой страницы нажмите кнопку **создать** , чтобы создать экземпляр этой службы.

    ![Создание службы LUIS — Юридическая информация](images/AzureLabs-Lab3-02.png)
 
4.  После нажатия кнопки Создать:

    1. Вставьте нужное **имя** для этого экземпляра службы.
    2. Выберите **подписку** .
    3. Выберите **ценовую категорию** , подходящую для вас. Если вы впервые создаете *службу Luis* , вам будет доступен бесплатный уровень (с именем F0). Для этого курса Свободное выделение должно быть больше, чем достаточно.
    4. Выберите **группу ресурсов** или создайте новую. Группа ресурсов предоставляет способ мониторинга, контроля доступа, подготовки счетов и управления ими для коллекции ресурсов Azure. Рекомендуется размещать все службы Azure, связанные с одним проектом (например, такие курсы), в общей группе ресурсов. 

        > Если вы хотите ознакомиться с дополнительными сведениями о группах ресурсов Azure, обратитесь [к статье о группе ресурсов](https://docs.microsoft.com/azure/azure-resource-manager/resource-group-portal).

    5. Определите **Расположение** группы ресурсов (при создании новой группы ресурсов). В идеале это расположение будет находиться в регионе, в котором будет выполняться приложение. Некоторые ресурсы Azure доступны только в определенных регионах.
    6. Также необходимо подтвердить, что вы поняли условия, примененные к этой службе.
    7. Нажмите кнопку **создания** .

        ![Создание службы LUIS. ввод пользователя](images/AzureLabs-Lab3-03.png)
 
5.  После нажатия кнопки **создать** необходимо подождать, пока не будет создана служба, а это может занять некоторое время.
6.  После создания экземпляра службы на портале отобразится уведомление. 
 
    ![Новый образ уведомлений Azure](images/AzureLabs-Lab3-04.png)

7.  Щелкните уведомление, чтобы просмотреть новый экземпляр службы.

    ![Уведомление об успешном создании ресурса](images/AzureLabs-Lab3-05.png)
 
8.  Нажмите кнопку " **Переход к ресурсу** " в уведомлении, чтобы изучить новый экземпляр службы. Вы будете перенаправлены на новый экземпляр службы LUIS. 
 
    ![Доступ к ключам LUIS](images/AzureLabs-Lab3-06.png)

9.  В рамках этого руководства приложение должно будет вызывать службу, что выполняется с помощью ключа подписки вашей службы.
10. На странице *быстрого запуска* службы *API Luis* перейдите к первому шагу, *Возьмите ключи* и щелкните **ключи** (это можно также сделать, щелкнув синие клавиши-гиперссылки, расположенные в меню навигации службы, обозначенном значком ключа). При этом будут раскрыты *ключи* службы.
11. Сделайте копию одного из отображаемых ключей, так как это потребуется позже в проекте. 
12. На странице *Служба* щелкните *Language Understanding портал* для перенаправления на веб-страницу, которая будет использоваться для создания новой службы в приложении Luis. 

## <a name="chapter-2--the-language-understanding-portal"></a>Глава 2 — портал Language Understanding

В этом разделе вы узнаете, как создать приложение LUIS на портале LUIS. 

> [!IMPORTANT]
> Имейте в виду, что настройка *сущностей* , *целей* и *фразы продолжительностью* в этой главе является только первым шагом в создании службы Luis. Вам также потребуется заново обучить службу, чтобы сделать ее более точной. Переобучение службы описано в [последней главе](#chapter-12--improving-your-luis-service) этого курса, поэтому убедитесь, что вы завершили его.

1.  При достижении *Language Understanding портала* вам может потребоваться выполнить вход, если вы еще не сделали этого, с теми же учетными данными, что и у портал Azure. 

    ![Страница входа в LUIS](images/AzureLabs-Lab3-07.png)
 
2.  Если вы впервые используете LUIS, необходимо прокрутить вниз до нижней части страницы приветствия, чтобы найти и нажать кнопку **создать приложение Luis** .

    ![Страница создания приложения LUIS](images/AzureLabs-Lab3-08.png)
 
3.  После входа в систему щелкните **Мои приложения** (если вы не в этом разделе сейчас). Затем можно щелкнуть **создать новое приложение** .

    ![LUIS — образ "Мои приложения"](images/AzureLabs-Lab3-09.png)
 
4.  Присвойте *имя* приложению.
5.  Если ваше приложение должно понимать язык, отличающийся от английского, следует изменить язык *и региональные параметры* на соответствующий.
6.  Здесь можно также добавить *Описание* нового приложения Luis.

    ![LUIS — создание нового приложения](images/AzureLabs-Lab3-10.png)

7.  После нажатия кнопки " **Готово** " вы введете страницу *сборки* нового приложения *Luis* .
8.  Существует несколько важных концепций, которые необходимо понять:

    -   *Намерение* представляет метод, который будет вызываться после запроса от пользователя. *Намерение* может иметь одну или несколько *сущностей* .
    -   *Entity* — это компонент запроса, который описывает сведения, относящиеся к *намерениям* .
    -   *Фразы продолжительностью* — примеры запросов, предоставляемых разработчиком, которые Luis будут использовать для обучения.

Если эти понятия не вполне понятны, не беспокойтесь, так как этот курс прояснить их в этой главе.

Начнем с создания *сущностей* , необходимых для создания этого курса.

9.  В левой части страницы щелкните *сущности* , а затем — **создать новую сущность** .

    ![Создать новую сущность](images/AzureLabs-Lab3-11.png)

10. Вызовите новый *Цвет* сущности, задайте для его типа значение *Simple* , а затем нажмите кнопку **Готово** .

    ![Создание простого объекта-цвета](images/AzureLabs-Lab3-12.png)
 
11. Повторите эту процедуру, чтобы создать три (3) более простые сущности с именем:

    -   *Размер*
    -   *уменьшать их размер*
    -   *target*

Результат должен выглядеть следующим образом:

![Результат создания сущности](images/AzureLabs-Lab3-13.png)
 
На этом этапе можно приступить к созданию *целей* . 

> [!WARNING]
> Не удаляйте цель **None** .

12. В левой части страницы щелкните **цели, а затем —** **создать новое намерение** .

    ![Создание новых целей](images/AzureLabs-Lab3-14.png)

13. Вызовите новый *намеренный* **чанжеобжектколор** .

    > [!IMPORTANT]
    > Это имя *намерения* используется в коде далее в этом курсе, поэтому для получения наилучших результатов используйте это имя точно так же, как указано.

Подтвердите имя, которое будет направляться на страницу «способы».

![LUIS — страница «намерения»](images/AzureLabs-Lab3-15.png)

Вы заметите, что у вас есть текстовое поле с предложением ввести 5 или более различных *фразы продолжительностью* .

> [!NOTE]
> LUIS преобразует все фразы продолжительностью в нижний регистр.

14. Вставьте следующий *utterance* в верхнее текстовое поле (в настоящее время с текстом *типа 5 примеров...* ) и нажмите клавишу **Ввод** :

```
The color of the cylinder must be red
```

Вы увидите, что новый *utterance* появится в списке под.

После того же процесса вставьте следующие шесть (6) фразы продолжительностью:

```
make the cube black

make the cylinder color white

change the sphere to red

change it to green

make this yellow

change the color of this object to blue
```

Для каждого созданного utterance необходимо указать, какие слова должны использоваться LUIS в качестве сущностей. В этом примере необходимо пометить все цвета как сущность *цвета* и все возможные ссылки на целевой объект в качестве *целевой* сущности.

15. Для этого попробуйте щелкнуть *цилиндр* на слове в первом utterance и выбрать *целевой объект* .

    ![Определяет целевые объекты utterance](images/AzureLabs-Lab3-16.png)
 
16. Теперь щелкните слово *Red* в первом utterance и выберите *Цвет* .

    ![Поиск сущностей utterance](images/AzureLabs-Lab3-17.png)
 
17. Метка Следующая строка также, где *куб* должен быть *целевым объектом* , а *черный* должен быть *цветом* . Также обратите внимание на использование слов *this* , *"IT* " и *"this Object"* , которые мы предоставляем, поэтому для неконкретных целевых типов также доступны. 

18. Повторите описанный выше процесс, пока все фразы продолжительностью не помечаются сущностями. Если вам нужна помощь, см. рисунок ниже.

    > [!TIP]
    > Выбрав слова, которые следует пометить, как сущности, сделайте следующее:
    > - Для отдельных слов просто щелкните их.
    > - Для набора из двух или более слов щелкните в начале, а затем в конце набора.

    > [!NOTE]
    > Для переключения между **представлениями сущностей и маркеров** можно использовать выключатель *представления маркеров* .

19. Результаты должны быть показаны на приведенных ниже изображениях, в которых отображается **представление "сущности и маркеры** ":

    ![Маркеры & представления сущностей](images/AzureLabs-Lab3-18.png)
  
20. На этом этапе нажмите кнопку " **обучение** " в правом верхнем углу страницы и дождитесь, чтобы индикатор небольшого круга был включен зеленым цветом. Это означает, что LUIS успешно обучена для распознавания этой цели.

    ![Обучение LUIS](images/AzureLabs-Lab3-19.png)
 
21. В качестве упражнения создайте новую цель с именем **чанжеобжектсизе** , используя *целевые* объекты, *Размер* и *уменьшать их размер* .
22. Следуя тому же процессу, что и в предыдущем намерении, вставьте следующие восемь (8) фразы продолжительностью для изменения *размера* :

    ```
    increase the dimensions of that

    reduce the size of this

    i want the sphere smaller

    make the cylinder bigger

    size down the sphere

    size up the cube

    decrease the size of that object

    increase the size of this object
    ```

23. Результат должен быть подобен показанному на рисунке ниже:

    ![Настройка маркеров и сущностей Чанжеобжектсизе](images/AzureLabs-Lab3-20.png) 

24. После создания и обучения обоих целей, **чанжеобжектколор** и **чанжеобжектсизе** , нажмите кнопку **опубликовать** в верхней части страницы.

    ![Публикация службы LUIS](images/AzureLabs-Lab3-21.png)

25. На странице *Публикация* вы завершите и опубликуете приложение Luis, чтобы к нему можно было получить доступ с помощью вашего кода.

    1. Установите в раскрывающемся списке *опубликовать* значение как **Рабочая** .
    2. Задайте *часовой* пояс в качестве часового пояса.
    3. Установите флажок **все оценки предполагаемых намерения** .
    4. Щелкните **опубликовать в рабочем слоте** .

        ![Публикация: параметры](images/AzureLabs-Lab3-22.png)

26. В разделе *ресурсы и ключи* :

    1.  Выберите регион, заданный для экземпляра службы на портале Azure.
    2.  Обратите внимание на элемент **Starter_Key** ниже, игнорируя его.
    3.  Щелкните **Добавить ключ** и вставьте *ключ* , полученный на портале Azure, при создании экземпляра службы. Если Azure и портал LUIS вошли в систему одного и того же пользователя, вам будут предоставлены раскрывающиеся меню для *имени клиента* , *имени подписки* и *ключа* , которые вы хотите использовать (имя будет совпадать с именем, которое вы указали ранее на портале Azure).

    > [!IMPORTANT] 
    > В нижней *конечной точке* Возьмите копию конечной точки, соответствующей вставленному ключу, вскоре вы будете использовать его в своем коде.
 
## <a name="chapter-3--set-up-the-unity-project"></a>Глава 3 — Настройка проекта Unity

Ниже приведена типичная Настройка для разработки с использованием смешанной реальности, которая является хорошим шаблоном для других проектов.

1.  Откройте *Unity* и нажмите кнопку **создать** . 

    ![Запуск нового проекта Unity.](images/AzureLabs-Lab3-24.png)

2.  Теперь необходимо указать имя проекта Unity, вставить **MR_LUIS** . Убедитесь, что для типа проекта задано значение **3D** . Задайте для **расположения нужное расположение** (Помните, что ближе к корневым каталогам лучше). Затем нажмите кнопку **создать проект** .

    ![Укажите сведения о новом проекте Unity.](images/AzureLabs-Lab3-25.png)
 
3.  При открытом Unity стоит проверить, что для **редактора скриптов** по умолчанию задано значение **Visual Studio** . Перейдите к разделу Изменение параметров >, а затем в новом окне перейдите к разделу **Внешние инструменты** . Измените **Редактор внешних скриптов** на **Visual Studio 2017** . Закройте окно **настройки** .

    ![Обновить настройки редактора скриптов.](images/AzureLabs-Lab3-26.png)
 
4.  Затем перейдите в раздел **файл > параметры сборки** и переключите платформу на **универсальная платформа Windows** , нажав кнопку **коммутатора платформы** .

    ![Окно "параметры сборки". Переключите платформу в UWP.](images/AzureLabs-Lab3-27.png)
 
5.  Перейдите в раздел **файл > параметры сборки** и убедитесь в том, что:

    1. **Целевое устройство** настроено для **любого устройства**

        > Для Microsoft HoloLens задайте для параметра **целевое устройство** значение *HoloLens* .

    2. Для **типа сборки** задано значение **D3D**
    3. **Пакет SDK** установлен в значение " **Последняя установка** "
    4. Для **версии Visual Studio** установлено значение " **Последняя установка** "
    5. **Сборка и запуск** настроены на **локальный компьютер**
    6. Сохраните сцену и добавьте ее в сборку.

        1. Для этого выберите **Добавить открытые сцены** . Появится окно сохранения.
        
            ![Нажмите кнопку Добавить кнопку "открыть сцены"](images/AzureLabs-Lab3-28.png)

        2. Создайте новую папку для этого, а также любой будущей сцены, а затем нажмите кнопку **создать папку** , чтобы создать новую папку, назовите ее « **сцены** ».

            ![Создать новую папку скриптов](images/AzureLabs-Lab3-29.png)

        3. Откройте только что созданную папку **сцены** , а затем в поле *имя файла* : введите **MR_LuisScene** , а затем нажмите кнопку **сохранить** .

            ![Присвойте имя новой сцене.](images/AzureLabs-Lab3-30.png)

    7. Оставшиеся параметры, в *параметрах сборки* , должны быть оставлены по умолчанию.

6. В окне *параметры сборки* нажмите кнопку **Параметры проигрывателя** , чтобы открыть связанную панель в пространстве, где находится *инспектор* . 

    ![Откройте параметры проигрывателя.](images/AzureLabs-Lab3-31.png) 
 
7. На этой панели необходимо проверить несколько параметров:

    1. На вкладке **другие параметры** выполните следующие действия.

        1. **Версия среды выполнения сценариев** должна быть **стабильной** (эквивалент .NET 3,5).
        2. **Серверная часть сценариев** должна быть **.NET**
        3. **Уровень совместимости API** должен быть **.NET 4,6**

            ![Обновите другие параметры.](images/AzureLabs-Lab3-32.png)
      
    2. На вкладке **Параметры публикации** в разделе **возможности** установите флажок:

        1. **InternetClient** ;
        2. **Микрофон**

            ![Обновляются параметры публикации.](images/AzureLabs-Lab3-33.png)

    3. На более низких панели в **параметрах XR** (см. ниже **Параметры публикации** ), **поддерживаемая виртуальная реальность** Tick, убедитесь, что добавлен **пакет SDK для Windows Mixed Reality** .

        ![Обновите параметры X R.](images/AzureLabs-Lab3-34.png)

8.  Назад в *параметрах сборки* проекты _C# Unity_ больше не заключаются; Установите флажок рядом с этим. 
9.  Закройте окно Build Settings (Параметры сборки).
10. Сохраните сцену и проект ( **файл > сохранить сцену или файл > сохранить проект** ).

## <a name="chapter-4--create-the-scene"></a>Глава 4 — Создание сцены

> [!IMPORTANT]
> Если вы хотите пропустить компонент *установки Unity, установленный* в этом курсе, и продолжить работу с кодом, скачайте этот файл [. пакет unitypackage](https://github.com/Microsoft/HolographicAcademy/raw/Azure-MixedReality-Labs/Azure%20Mixed%20Reality%20Labs/MR%20and%20Azure%20303%20-%20Natural%20language%20understanding/Azure-MR-303.unitypackage), импортируйте его в проект как [пользовательский пакет](https://docs.unity3d.com/Manual/AssetPackages.html), а затем продолжайте в [главе 5](#chapter-5--create-the-microphonemanager-class). 

1.  Щелкните правой кнопкой мыши пустую область *панели Иерархия* в разделе **трехмерный объект** , добавьте **плоскость** .

    ![Создайте плоскость.](images/AzureLabs-Lab3-35.png)

2.  Имейте в виду, что если щелкнуть правой кнопкой мыши в *иерархии* , чтобы создать больше объектов, то если последний объект по-прежнему выбран, то выбранный объект будет родительским для нового объекта. Избегайте щелчка левой кнопкой мыши в пустом пространстве внутри иерархии, а затем щелкните правой клавишей.

3.  Повторите описанную выше процедуру, чтобы добавить следующие объекты:

    1. *Sphere*
    2. *Цилиндр*
    3. *Cube*
    4. *Объемный текст*

4.  Итоговая *Иерархия* сцены должна быть похожа на показанную на рисунке ниже:

    ![Настройка иерархии сцены.](images/AzureLabs-Lab3-36.png)
 
5.  Щелкните на **основной камере** , чтобы выбрать ее. на *панели инспектора* вы увидите объект Camera со всеми компонентами.
6.  Нажмите кнопку **Добавить компонент** , расположенную в самом низу *панели инспектора* .

    ![Добавить источник звука](images/AzureLabs-Lab3-37.png)
 
7.  Найдите компонент « *источник звука* », как показано выше.
8.  Также убедитесь, что компонент *преобразования* основной камеры имеет значение (0, 0, 0). это можно сделать, нажав значок **шестеренки** рядом с компонентом *преобразования* камеры и выбрав **Сброс** . Компонент *преобразования* должен выглядеть следующим образом:

    1.  Для параметра *положением* задано значение **0, 0, 0** .
    2.  Для *вращения* задано значение **0, 0, 0** .

    > [!NOTE] 
    > Для Microsoft HoloLens необходимо также изменить следующие компоненты, которые являются частью компонента **камеры** , расположенного на **основной камере** :
    > - **Снять флаги:** Сплошной цвет.
    > - **Фоновый режим** "Черный, альфа 0" — шестнадцатеричный цвет: #00000000.

9.  Щелкните **плоскость** левой кнопкой мыши, чтобы выбрать ее. На *панели инспектора* установите компонент *преобразования* со следующими значениями:

    |   Ось X    | Ось Y |   Ось Z    |
    |:-----:|:----------------------:|:-----:|
    | 0     | -1                     | 0     |


10. Щелкните **сферу** левой кнопкой мыши, чтобы выбрать ее. На *панели инспектора* установите компонент *преобразования* со следующими значениями:

    |   Ось X    | Ось Y |   Ось Z    |
    |:-----:|:----------------------:|:-----:|
    | 2     | 1                      | 2     |

11. Щелкните **цилиндр** левой кнопкой мыши, чтобы выделить ее. На *панели инспектора* установите компонент *преобразования* со следующими значениями:

    |   Ось X    | Ось Y |   Ось Z    |
    |:-----:|:----------------------:|:-----:|
    | -2    | 1                      | 2     |

12. Щелкните **куб** левой кнопкой мыши, чтобы выбрать его. На *панели инспектора* установите компонент *преобразования* со следующими значениями:

    |        | Transform- *позиционирование* |       |  \| |       | *Поворот* преобразования |       |
    |:------:|:----------------------:|:-----:|:---:|:-----:|:----------------------:|:-----:|
    | **X** | **да**                   | **Z** |  \| | **X** | **да**                  | **Z** |
    | 0     | 1                       | 4     |  \| | 45    | 45                     | 0     | 

13. Щелкните **новый текстовый** объект левой кнопкой мыши, чтобы выбрать его. На *панели инспектора* установите компонент *преобразования* со следующими значениями:

    |       | Transform- *позиционирование* |       |  \| |       | Преобразование — *масштабирование* |       |
    |:-----:|:----------------------:|:-----:|:---:|:-----:|:-------------------:|:-----:|
    | **X** | **да**                  | **Z** |  \| | **X** | **да**               | **Z** |
    | -2    | 6                      | 9     |  \| | 0,1   | 0,1                 | 0,1   | 

14. Измените **Размер шрифта** в компоненте **сетки текста** на **50** .
15. Измените *имя* объекта **сетки текста** на **текст диктовки** .

    ![Создать трехмерный текстовый объект](images/AzureLabs-Lab3-38.png)
 
16. Теперь структура панели иерархии должна выглядеть следующим образом:

    ![сетка текста в представлении сцены](images/AzureLabs-Lab3-38b.png)


17. Окончательная сцена должна выглядеть следующим образом:

    ![Представление сцены.](images/AzureLabs-Lab3-39.png)
    
 
## <a name="chapter-5--create-the-microphonemanager-class"></a>Глава 5 — Создание класса Микрофонеманажер

Первым создаваемым сценарием является класс *микрофонеманажер* . После этого вы создадите *луисманажер* , класс *поведений* и, наконец, класс *взгляда* (вы можете создать все эти данные сейчас, хотя он будет охватывать каждую главу).

Класс *микрофонеманажер* отвечает за:

-   Обнаружение устройства записи, подключенного к гарнитуре или компьютеру (в зависимости от того, какое значение используется по умолчанию).
-   Запишите звук (голосовой) и используйте диктовку, чтобы сохранить ее в виде строки.
-   После приостановки голоса отправьте диктовку в класс *луисманажер* . 

Чтобы создать этот класс, сделайте следующее: 

1.  Щелкните правой кнопкой мыши на *панели проект* , **Создайте папку >** . Вызовите **скрипты** папки. 

    ![Создайте папку Scripts.](images/AzureLabs-Lab3-40.png)
 
2.  После создания папки **Scripts (скрипты** ) дважды щелкните ее, чтобы открыть. Затем в этой папке щелкните правой кнопкой мыши, **создайте > скрипт C#** . Назовите сценарий *микрофонеманажер* . 

3.  Дважды щелкните *микрофонеманажер* , чтобы открыть его в *Visual Studio* .
4.  Добавьте следующие пространства имен в начало файла:

    ```csharp
        using UnityEngine;
        using UnityEngine.Windows.Speech;
    ```

5.  Затем добавьте следующие переменные в класс *микрофонеманажер* :

    ```csharp
        public static MicrophoneManager instance; //help to access instance of this object
        private DictationRecognizer dictationRecognizer;  //Component converting speech to text
        public TextMesh dictationText; //a UI object used to debug dictation result
    ``` 

6.  Теперь необходимо добавить код для методов *"спящий" ()* и *"начало" ()* . Они будут вызываться при инициализации класса:

    ```csharp
        private void Awake()
        {
            // allows this class instance to behave like a singleton
            instance = this;
        }

        void Start()
        {
            if (Microphone.devices.Length > 0)
            {
                StartCapturingAudio();
                Debug.Log("Mic Detected");
            }
        }
    ```
 
7.  Теперь вам нужен метод, который приложение использует для запуска и завершения записи речи, и передать его в класс *луисманажер* , который скоро будет создан. 

    ```csharp
        /// <summary>
        /// Start microphone capture, by providing the microphone as a continual audio source (looping),
        /// then initialise the DictationRecognizer, which will capture spoken words
        /// </summary>
        public void StartCapturingAudio()
        {
            if (dictationRecognizer == null)
            {
                dictationRecognizer = new DictationRecognizer
                {
                    InitialSilenceTimeoutSeconds = 60,
                    AutoSilenceTimeoutSeconds = 5
                };

                dictationRecognizer.DictationResult += DictationRecognizer_DictationResult;
                dictationRecognizer.DictationError += DictationRecognizer_DictationError;
            }
            dictationRecognizer.Start();
            Debug.Log("Capturing Audio...");
        }

        /// <summary>
        /// Stop microphone capture
        /// </summary>
        public void StopCapturingAudio()
        {
            dictationRecognizer.Stop();
            Debug.Log("Stop Capturing Audio...");
        }
    ```

8.  Добавьте *обработчик диктовки* , который будет вызываться при приостановке голоса. Этот метод передаст текст диктовки в класс *луисманажер* .

    ```csharp
        /// <summary>
        /// This handler is called every time the Dictation detects a pause in the speech. 
        /// This method will stop listening for audio, send a request to the LUIS service 
        /// and then start listening again.
        /// </summary>
        private void DictationRecognizer_DictationResult(string dictationCaptured, ConfidenceLevel confidence)
        {
            StopCapturingAudio();
            StartCoroutine(LuisManager.instance.SubmitRequestToLuis(dictationCaptured, StartCapturingAudio));
            Debug.Log("Dictation: " + dictationCaptured);
            dictationText.text = dictationCaptured;
        }

        private void DictationRecognizer_DictationError(string error, int hresult)
        {
            Debug.Log("Dictation exception: " + error);
        }
    ```
 
    > [!IMPORTANT]
    > Удалите метод *Update ()* , так как этот класс не будет его использовать.

9.  Не забудьте сохранить изменения в *Visual Studio* перед возвратом в *Unity* .

    > [!NOTE]
    > На этом этапе вы увидите ошибку на *панели консоли редактора Unity* . Это обусловлено тем, что код ссылается на класс *луисманажер* , который будет создан в следующей главе.

## <a name="chapter-6--create-the-luismanager-class"></a>Глава 6 — создание класса Луисманажер

Пора создать класс *луисманажер* , который сделает вызов в службу Azure Luis. 

Этот класс предназначен для получения текста диктовки от класса *микрофонеманажер* и отправки его в *API распознавания речи Azure* для анализа.

Этот класс будет десериализовать ответ *JSON* и вызвать соответствующие методы класса *поведений* , чтобы активировать действие.

Чтобы создать этот класс, сделайте следующее: 

1.  Дважды щелкните папку **Scripts** , чтобы открыть ее. 
2.  Щелкните правой кнопкой мыши в папке **Scripts** и выберите **создать > скрипт C#** . Назовите сценарий *луисманажер* . 
3.  Дважды щелкните скрипт, чтобы открыть его в Visual Studio.
4.  Добавьте следующие пространства имен в начало файла:

    ```csharp
        using System;
        using System.Collections;
        using System.Collections.Generic;
        using System.IO;
        using UnityEngine;
        using UnityEngine.Networking;
    ```

5.  Начнем с создания трех классов **внутри** класса *луисманажер* (в рамках одного файла скрипта выше метода *Start ()* ), который будет представлять Десериализованный ответ JSON из Azure.

    ```csharp
        [Serializable] //this class represents the LUIS response
        public class AnalysedQuery
        {
            public TopScoringIntentData topScoringIntent;
            public EntityData[] entities;
            public string query;
        }

        // This class contains the Intent LUIS determines 
        // to be the most likely
        [Serializable]
        public class TopScoringIntentData
        {
            public string intent;
            public float score;
        }

        // This class contains data for an Entity
        [Serializable]
        public class EntityData
        {
            public string entity;
            public string type;
            public int startIndex;
            public int endIndex;
            public float score;
        }
    ```

6.  Затем добавьте следующие переменные в класс *луисманажер* :
 
    ```csharp
        public static LuisManager instance;

        //Substitute the value of luis Endpoint with your own End Point
        string luisEndpoint = "https://westus.api.cognitive... add your endpoint from the Luis Portal";
    ```

7.  Обязательно поместите конечную точку LUIS в сейчас (которая получится на портале LUIS).

8.  Теперь необходимо добавить код для метода " *спящий ()* ". Этот метод будет вызываться при инициализации класса:

    ```csharp
        private void Awake()
        {
            // allows this class instance to behave like a singleton
            instance = this;
        }
    ```

9.  Теперь вам потребуются методы, которые приложение использует для отправки диктовки, полученной от класса *микрофонеманажер* , в *Luis* , а затем получения и десериализации ответа. 
10. После определения цели и связанных сущностей они передаются в экземпляр класса *поведений* , чтобы активировать предполагаемое действие.

    ```csharp
        /// <summary>
        /// Call LUIS to submit a dictation result.
        /// The done Action is called at the completion of the method.
        /// </summary>
        public IEnumerator SubmitRequestToLuis(string dictationResult, Action done)
        {
            string queryString = string.Concat(Uri.EscapeDataString(dictationResult));

            using (UnityWebRequest unityWebRequest = UnityWebRequest.Get(luisEndpoint + queryString))
            {
                yield return unityWebRequest.SendWebRequest();

                if (unityWebRequest.isNetworkError || unityWebRequest.isHttpError)
                {
                    Debug.Log(unityWebRequest.error);
                }
                else
                {
                    try
                    {
                        AnalysedQuery analysedQuery = JsonUtility.FromJson<AnalysedQuery>(unityWebRequest.downloadHandler.text);

                        //analyse the elements of the response 
                        AnalyseResponseElements(analysedQuery);
                    }
                    catch (Exception exception)
                    {
                        Debug.Log("Luis Request Exception Message: " + exception.Message);
                    }
                }

                done();
                yield return null;
            }
        }
    ```
 
11. Создайте новый метод с именем *аналисереспонсилементс ()* , который будет считывать результирующий *Аналиседкуери* и определять сущности. После определения этих сущностей они будут переданы в экземпляр класса *поведений* для использования в действиях.

    ```csharp
        private void AnalyseResponseElements(AnalysedQuery aQuery)
        {
            string topIntent = aQuery.topScoringIntent.intent;

            // Create a dictionary of entities associated with their type
            Dictionary<string, string> entityDic = new Dictionary<string, string>();

            foreach (EntityData ed in aQuery.entities)
            {
                entityDic.Add(ed.type, ed.entity);
            }

            // Depending on the topmost recognized intent, read the entities name
            switch (aQuery.topScoringIntent.intent)
            {
                case "ChangeObjectColor":
                    string targetForColor = null;
                    string color = null;

                    foreach (var pair in entityDic)
                    {
                        if (pair.Key == "target")
                        {
                            targetForColor = pair.Value;
                        }
                        else if (pair.Key == "color")
                        {
                            color = pair.Value;
                        }
                    }

                    Behaviours.instance.ChangeTargetColor(targetForColor, color);
                    break;

                case "ChangeObjectSize":
                    string targetForSize = null;
                    foreach (var pair in entityDic)
                    {
                        if (pair.Key == "target")
                        {
                            targetForSize = pair.Value;
                        }
                    }

                    if (entityDic.ContainsKey("upsize") == true)
                    {
                        Behaviours.instance.UpSizeTarget(targetForSize);
                    }
                    else if (entityDic.ContainsKey("downsize") == true)
                    {
                        Behaviours.instance.DownSizeTarget(targetForSize);
                    }
                    break;
            }
        }
    ```
 
    > [!IMPORTANT]
    > Удалите методы *Start ()* и *Update ()* , так как этот класс не будет использовать их.

12. Не забудьте сохранить изменения в *Visual Studio* перед возвратом в *Unity* .

> [!NOTE]
> На этом этапе вы увидите несколько ошибок на *панели консоли редактора Unity* . Это обусловлено тем, что код ссылается на класс *поведения* , который будет создан в следующей главе.

## <a name="chapter-7--create-the-behaviours-class"></a>Глава 7 — создание класса поведения

Класс *поведений* активирует действия с помощью сущностей, предоставляемых классом *луисманажер* .

Чтобы создать этот класс, сделайте следующее: 

1.  Дважды щелкните папку **Scripts** , чтобы открыть ее. 
2.  Щелкните правой кнопкой мыши в папке **Scripts** и выберите **создать > скрипт C#** . Назовите *поведение* сценария. 
3.  Дважды щелкните скрипт, чтобы открыть его в *Visual Studio* .
4.  Затем добавьте следующие переменные в класс *поведения* :

    ```csharp
        public static Behaviours instance;

        // the following variables are references to possible targets
        public GameObject sphere;
        public GameObject cylinder;
        public GameObject cube;
        internal GameObject gazedTarget;
    ```
 
5.  Добавьте код метода " *спящий ()* ". Этот метод будет вызываться при инициализации класса:

    ```csharp
        void Awake()
        {
            // allows this class instance to behave like a singleton
            instance = this;
        }
    ```
 
6.  Следующие методы вызываются классом *луисманажер* (который был создан ранее), чтобы определить, какой объект является целевым объектом запроса, и затем активировать соответствующее действие.

    ```csharp
        /// <summary>
        /// Changes the color of the target GameObject by providing the name of the object
        /// and the name of the color
        /// </summary>
        public void ChangeTargetColor(string targetName, string colorName)
        {
            GameObject foundTarget = FindTarget(targetName);
            if (foundTarget != null)
            {
                Debug.Log("Changing color " + colorName + " to target: " + foundTarget.name);

                switch (colorName)
                {
                    case "blue":
                        foundTarget.GetComponent<Renderer>().material.color = Color.blue;
                        break;

                    case "red":
                        foundTarget.GetComponent<Renderer>().material.color = Color.red;
                        break;

                    case "yellow":
                        foundTarget.GetComponent<Renderer>().material.color = Color.yellow;
                        break;

                    case "green":
                        foundTarget.GetComponent<Renderer>().material.color = Color.green;
                        break;

                    case "white":
                        foundTarget.GetComponent<Renderer>().material.color = Color.white;
                        break;

                    case "black":
                        foundTarget.GetComponent<Renderer>().material.color = Color.black;
                        break;
                }          
            }
        }

        /// <summary>
        /// Reduces the size of the target GameObject by providing its name
        /// </summary>
        public void DownSizeTarget(string targetName)
        {
            GameObject foundTarget = FindTarget(targetName);
            foundTarget.transform.localScale -= new Vector3(0.5F, 0.5F, 0.5F);
        }

        /// <summary>
        /// Increases the size of the target GameObject by providing its name
        /// </summary>
        public void UpSizeTarget(string targetName)
        {
            GameObject foundTarget = FindTarget(targetName);
            foundTarget.transform.localScale += new Vector3(0.5F, 0.5F, 0.5F);
        }
    ```
 
7.  Добавьте метод *финдтаржет ()* , чтобы определить, какой из *объекты gameobject* является целевым объектом текущей цели. Этот метод по умолчанию имеет значение "газед" для целевого объекта *GameObject* , если в сущностях не определена явная цель.

    ```csharp
        /// <summary>
        /// Determines which object reference is the target GameObject by providing its name
        /// </summary>
        private GameObject FindTarget(string name)
        {
            GameObject targetAsGO = null;

            switch (name)
            {
                case "sphere":
                    targetAsGO = sphere;
                    break;

                case "cylinder":
                    targetAsGO = cylinder;
                    break;

                case "cube":
                    targetAsGO = cube;
                    break;

                case "this": // as an example of target words that the user may use when looking at an object
                case "it":  // as this is the default, these are not actually needed in this example
                case "that":
                default: // if the target name is none of those above, check if the user is looking at something
                    if (gazedTarget != null) 
                    {
                        targetAsGO = gazedTarget;
                    }
                    break;
            }
            return targetAsGO;
        }
    ```
 
    > [!IMPORTANT]
    > Удалите методы *Start ()* и *Update ()* , так как этот класс не будет использовать их.

8.  Не забудьте сохранить изменения в *Visual Studio* перед возвратом в *Unity* .

## <a name="chapter-8--create-the-gaze-class"></a>Глава 8 — Создание класса «взгляд»

Последним классом, который потребуется для завершения этого приложения, является класс « *взгляд* ». Этот класс обновляет ссылку на *GameObject* в данный момент в визуальном фокусе пользователя.

Чтобы создать этот класс, сделайте следующее: 

1.  Дважды щелкните папку **Scripts** , чтобы открыть ее. 
2.  Щелкните правой кнопкой мыши в папке **Scripts** и выберите **создать > скрипт C#** . Присвойте скрипту имя « *взгляд* ». 
3.  Дважды щелкните скрипт, чтобы открыть его в *Visual Studio* .
4.  Вставьте следующий код для этого класса:

    ```csharp
        using UnityEngine;

        public class Gaze : MonoBehaviour
        {        
            internal GameObject gazedObject;
            public float gazeMaxDistance = 300;

            void Update()
            {
                // Uses a raycast from the Main Camera to determine which object is gazed upon.
                Vector3 fwd = gameObject.transform.TransformDirection(Vector3.forward);
                Ray ray = new Ray(Camera.main.transform.position, fwd);
                RaycastHit hit;
                Debug.DrawRay(Camera.main.transform.position, fwd);

                if (Physics.Raycast(ray, out hit, gazeMaxDistance) && hit.collider != null)
                {
                    if (gazedObject == null)
                    {
                        gazedObject = hit.transform.gameObject;

                        // Set the gazedTarget in the Behaviours class
                        Behaviours.instance.gazedTarget = gazedObject;
                    }
                }
                else
                {
                    ResetGaze();
                }         
            }

            // Turn the gaze off, reset the gazeObject in the Behaviours class.
            public void ResetGaze()
            {
                if (gazedObject != null)
                {
                    Behaviours.instance.gazedTarget = null;
                    gazedObject = null;
                }
            }
        }
    ```
 
5.  Не забудьте сохранить изменения в *Visual Studio* перед возвратом в *Unity* .

## <a name="chapter-9--completing-the-scene-setup"></a>Глава 9 — завершение настройки сцены

1.  Чтобы завершить настройку сцены, перетащите каждый созданный скрипт из папки сценарии в **основной объект Camera** на *панели Иерархия* .
2.  Выберите **основную камеру** и взгляните на *Панель инспектора* , вы сможете увидеть каждый присоединенный сценарий, и вы заметите, что в каждом скрипте есть параметры, которые еще не заданы.

    ![Настройка целевых объектов для ссылок на камеру.](images/AzureLabs-Lab3-41.png)

3.  Чтобы правильно задать эти параметры, выполните следующие действия:

    1. *Микрофонеманажер* :

        - На *панели Иерархия* перетащите текстовый объект **диктовки** в поле значение **текстового параметра диктовки** .

    2. *Поведение* на *панели Иерархия* :

        - Перетащите объект **Sphere** в поле Целевая ссылка на *сферу* .
        - Перетащите **цилиндр** в поле Целевая ссылка *цилиндра* .
        - Перетащите **куб** в поле Целевая ссылка на *куб* .

    3. *Взгляните* :

        - Установите *Максимальное расстояние от взгляда* до **300** (если оно еще не указано). 

4.  Результат должен выглядеть следующим образом:

    ![Показаны целевые объекты для ссылок на камеру, теперь задано.](images/AzureLabs-Lab3-42.png)
 
## <a name="chapter-10--test-in-the-unity-editor"></a>Глава 10 — тестирование в редакторе Unity

Проверьте, правильно ли реализована Настройка сцены.

Убедитесь в следующем:

-   Все скрипты присоединяются к **главному объекту Camera** . 
-   Все поля на *панели инспектора основной камеры* назначены должным образом.

1.  Нажмите кнопку **воспроизвести** в *редакторе Unity* . Приложение должно выполняться в присоединенной иммерсивного гарнитуре.

2.  Попробуйте несколько фразы продолжительностью, например:

    ```
    make the cylinder red

    change the cube to yellow

    I want the sphere blue

    make this to green

    change it to white
    ```

    > [!NOTE]
    > Если в консоли Unity появляется сообщение об ошибке о смене звукового устройства по умолчанию, возможно, сцена не работает должным образом. Это связано с тем, как портал смешанной реальности работает со встроенными микротелефонами для гарнитур, имеющих их. Если вы видите эту ошибку, просто закройте сцену и снова запустите ее, и она должна работать должным образом.

## <a name="chapter-11--build-and-sideload-the-uwp-solution"></a>Глава 11 — Создание и загружать неопубликованные решения UWP

После проверки того, что приложение работает в редакторе Unity, можно приступать к сборке и развертыванию.

Для сборки:

1.  Сохраните текущую сцену, щелкнув **файл > сохранить** .
2.  Выберите **файл > параметры сборки** .
3.  Установите флажок для **проектов Unity C#** (полезно для просмотра и отладки кода после создания проекта UWP).
4.  Щелкните **Добавить открытые сцены** , а затем — **Сборка** .

    ![Окно "параметры сборки"](images/AzureLabs-Lab3-43.png)

4.  Вам будет предложено выбрать папку, в которой нужно построить решение. 

5.  Создайте папку *Builds* и в этой папке создайте другую папку с соответствующим именем по своему усмотрению. 
6.  Щелкните **выбрать папку** , чтобы начать сборку в этом расположении.
 
    ![Создать папку сборок ](images/AzureLabs-Lab3-44.png)
     ![ Выбор папки сборок](images/AzureLabs-Lab3-45.png)
 
7.  После завершения сборки Unity (может занять некоторое время) он должен открыть окно **проводника** в расположении сборки.

Для развертывания на локальном компьютере:

1.  В *Visual Studio* откройте файл решения, который был создан в [предыдущей главе](#chapter-10--test-in-the-unity-editor).
2.  На **платформе решения** выберите **x86** , **локальный компьютер** .
3.  В **конфигурации решения** выберите **Отладка** .

    > Для Microsoft HoloLens может быть проще установить этот параметр на *Удаленный компьютер* , чтобы вы не были подключены к компьютеру. Однако необходимо также выполнить следующие действия.
    > - Определите **IP-адрес** HoloLens, который можно найти в *параметрах > сети & Интернет > Wi-Fi > дополнительные параметры* . IPv4 — это адрес, который следует использовать. 
    > - Убедитесь, **что включен** **режим разработчика** ; находится в *параметрах > Update & > безопасности для разработчиков* .

    ![Развертывание приложения](images/AzureLabs-Lab3-46.png)
 
4.  Перейдите в **меню "сборка** " и щелкните " **Развернуть решение** ", чтобы загружать неопубликованные приложение на компьютере.
5.  Теперь приложение должно отобразиться в списке установленных приложений, готовых к запуску.
6.  После запуска приложение предложит авторизовать доступ к _микрофону_ . Используйте *контроллеры движения* , *Ввод голоса* или *клавиатуру* , чтобы нажать кнопку **Да** . 

## <a name="chapter-12--improving-your-luis-service"></a>Глава 12 — улучшение службы LUIS

>[!IMPORTANT] 
> Эта глава чрезвычайно важна и, возможно, потребуется выполнить итерацию несколько раз, так как она поможет улучшить точность службы LUIS: Убедитесь, что вы выполнили это действие.

Чтобы улучшить уровень понимания, предоставляемый LUIS, необходимо захватить новый фразы продолжительностью и использовать их для повторного обучения приложения LUIS.

Например, вы могли обучить LUIS, чтобы понять "увеличение" и "размер", но не хотите, чтобы ваше приложение также понимало такие слова, как "увеличить"?

Когда вы будете использовать приложение несколько раз, все, что вы сказали, будет собрано LUIS и доступным на ПОРТАЛе LUIS.

1.  Перейдите в приложение портала, следуя этой [ссылке](https://www.luis.ai/home), и выполните вход.
2.  Войдя с учетными данными MS, щелкните *имя своего приложения* .
3.  Нажмите кнопку **проверить конечную точку фразы продолжительностью** в левой части страницы.

    ![Проверка фразы продолжительностью](images/AzureLabs-Lab3-47.png)
 
4.  Вы увидите список фразы продолжительностью, отправленных в LUIS приложением Mixed Reality.

    ![Список фразы продолжительностью](images/AzureLabs-Lab3-48.png)
 
Вы увидите некоторые выделенные *сущности* . 

Наведя указатель мыши на каждое выделенное слово, вы можете ознакомиться с каждым из utterance и определить, какая сущность распознана правильно, какие сущности являются неправильными и какие сущности пропущены.

В приведенном выше примере было обнаружено, что слово «Спиар» было выделено в качестве целевого объекта, поэтому необходимо исправить ошибку. это можно сделать, наведя указатель мыши на слово и выбрав пункт **Удалить метку** .

![Проверить ](images/AzureLabs-Lab3-49.png)
 ![ изображение удаления метки фразы продолжительностью](images/AzureLabs-Lab3-50.png)
 
5.  Если обнаружены неправильные фразы продолжительностью, их можно удалить с помощью кнопки **Удалить** в правой части экрана.

    ![Удалить неправильный фразы продолжительностью](images/AzureLabs-Lab3-51.png)

6.  Или, если вы считаете, что LUIS правильно интерпретирует utterance, можно проверить его понимание с помощью кнопки **Добавить в соответствие** .

    ![Добавить в согласованное назначение](images/AzureLabs-Lab3-52.png)

7.  После сортировки всех отображаемых фразы продолжительностью попробуйте перезагрузить страницу, чтобы узнать, доступны ли другие.
8.  Очень важно повторить этот процесс столько раз, сколько возможно, чтобы улучшить понимание приложения. 

**Желаю удачи!**

## <a name="your-finished-luis-integrated-application"></a>Готовое интегрированное приложение LUIS

Поздравляем! вы создали приложение смешанной реальности, которое использует службу Azure Language Understanding Intelligence, чтобы понять, что говорит пользователь, и действовать над этими сведениями.

![Результат лаборатории](images/AzureLabs-Lab3-000.png)

## <a name="bonus-exercises"></a>Премиальные упражнения

### <a name="exercise-1"></a>Упражнение 1

При использовании этого приложения вы можете заметить, что если взглянуть на объект Floor и попросить изменить его цвет, это сделает это. Можно ли узнать, как запретить приложению изменять цвет этажа?

### <a name="exercise-2"></a>Упражнение 2

Попробуйте расширить возможности LUIS и приложений, добавив дополнительные функции для объектов в сцене. в качестве примера можно создать новые объекты в точке попадания, в зависимости от того, что сообщает пользователь, а затем использовать эти объекты вместе с текущими объектами сцены с помощью существующих команд. 
