---
title: Использование речевых команд
description: Из этого курса вы узнаете, как создать, настроить и использовать речевые команды в приложениях смешанной реальности с помощью Mixed Reality Toolkit (MRTK).
author: jessemcculloch
ms.author: jemccull
ms.date: 02/05/2021
ms.topic: article
keywords: смешанная реальность, Unity, учебник, HoloLens, MRTK, Mixed Reality Toolkit, UWP, речевые команды, голосовой ввод
ms.localizationpriority: high
ms.openlocfilehash: 448dafbbfdea7ebec26cdafe6c638c37333bcf01399a8272d5637730469ab579
ms.sourcegitcommit: a1c086aa83d381129e62f9d8942f0fc889ffcab0
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 08/05/2021
ms.locfileid: "115192296"
---
# <a name="9-using-speech-commands"></a>9. Использование речевых команд

Из этого учебника вы узнаете, как создавать речевые команды и управлять ими глобально. Вы также узнаете, как управлять локальными речевыми командами, которые требуют от пользователя просмотра объекта, управляющего речевой командой.

## <a name="objectives"></a>Задачи

* Узнать, как создавать речевые команды.
* Узнать, как управлять речевыми командами на локальном и глобальном уровнях.

## <a name="ensuring-the-microphone-capability-is-enabled"></a>Активация функции микрофона

В меню Unity выберите Mixed Reality (Смешанная реальность) > Toolkit (Набор средств) > Utilities (Служебные программы) > **Configure Project for MRTK** (Настроить проект для MRTK), чтобы открыть окно **MRTK Project Configurator** (Конфигуратор проекта MRTK). Затем в разделе **UWP Capabilities** (Возможности UWP) проверьте, что параметр **Enable Microphone Capability** (Включить функцию микрофона) выделен серым цветом:

![Включение поддержки микрофона](images/mr-learning-base/base-09-section1-step1-1.png)

> [!NOTE]
> Во время выполнения инструкций по настройке проекта Unity из раздела [Применение параметров конфигуратора проекта MRTK](mr-learning-base-02.md#creating-the-scene-and-configuring-mrtk), приведенного в начале этого учебного курса, должна быть включена функция поддержки микрофона. Если функция отключена, включите ее сейчас.

## <a name="creating-speech-commands"></a>Создание речевых команд

В окне Hierarchy (Иерархия) выберите объект **MixedRealityToolkit**, затем в окне Inspector (Инспектор) перейдите на вкладку MixedRealityToolkit > **Input** (Ввод) и выполните следующие действия:

* Разверните раздел **Speech** (Речь).
* Клонируйте **DefaultMixedRealitySpeechCommandsProfile** и присвойте ему подходящее имя, например _GettingStarted_MixedRealitySpeechCommandsProfile_.
* Убедитесь, что параметр **Start Behaviour** (Поведение при запуске) имеет значение **Auto Start** (Автоматический запуск).

![Создание речевых команд](images/mr-learning-base/base-09-section2-step1-1.png)

> [!TIP]
> Сведения о том, как правильно клонировать профили MRTK, см. в статье [Настройка профилей MRTK](mr-learning-base-03.md).

В разделе Speech (Речь) > **Speech Commands** (Речевые команды) нажмите кнопку **+ Add a New Speech Command** (Добавить новую речевую команду) четыре раза, чтобы добавить четыре новые речевые команды в список существующих речевых команд, а затем в поле **Keyword** (Ключевое слово) введите такие фразы:

* Enable Indicator (Включить индикатор).
* Enable Tap to Place (Включить возможность размещения касанием).
* Включение управления границами
* Отключение управления границами

![Добавление новых речевых команд](images/mr-learning-base/base-09-section2-step1-2.png)

> [!TIP]
> Если на компьютере нет микрофона, можно задать для речевых команд код клавиши. Это позволит запускать их нажатием соответствующей клавиши.

## <a name="controlling-speech-commands"></a>Управление речевыми командами

В окне Project (Проект) перейдите к папке **Packages** > **Mixed Reality Toolkit Foundation** > **SDK** > **Features** > **UX** > **Prefabs** > **ToolTip**, чтобы найти заготовки подсказок:

![Открытие папки с подсказками](images/mr-learning-base/base-09-section3-step1-1.png)

Щелкните правой кнопкой мыши пустое место в окне Hierarchy (Иерархия) и выберите **Create Empty** (Создать пустой), чтобы добавить к сцене пустой объект.

Присвойте объекту имя **SpeechInputHandler_Global**, затем в окне Inspector (Инспектор) нажмите кнопку **Add Component** (Добавить компонент), чтобы добавить компонент **SpeechInputHandler**, и настройте его следующим образом:

* **Снимите флажок** в окне **Is Focus Required** (Требуется фокус), чтобы пользователь не видел объект с компонентом SpeechInputHandler для активации речевой команды.
* В окне Project (Проект) добавьте заготовку **SpeechConfirmation Tooltip** в поле **Speech Confirmation Tooltip Prefab** (Заготовка подсказки подтверждения голосом), чтобы эта заготовка отображалась при распознавании речевой команды.

![Настройка компонента обработчика речевого ввода](images/mr-learning-base/base-09-section3-step1-2.png)

В компоненте SpeechInputHandler щелкните маленький значок **+** три раза, чтобы добавить три элемента ключевого слова:

![Добавление элементов ключевых слов в обработчик речевого ввода](images/mr-learning-base/base-09-section3-step1-3.png)

Разверните пункт **Element 0** (Элемент 0) и настройте его следующим образом:

* В поле **Keyword** (Ключевое слово) введите **Enable Indicator** (Включить индикатор) для ссылки на речевую команду Enable Indicator (Включить индикатор), созданную в предыдущем разделе.
* Щелкните маленький значок **+** , чтобы добавить событие.
* В окне Hierarchy (Иерархия) укажите объект **Indicator** в поле **None (Object)** (Отсутствует (Объект)).
* В раскрывающемся списке **No Function** (Функция отсутствует) выберите **GameObject** > **SetActive (bool)** , чтобы задать эту функцию как действие, выполняемое при срабатывании события.
* Убедитесь, что **установлен** флажок аргумента.

![Настройка элемента ключевого слова 0](images/mr-learning-base/base-09-section3-step1-4.png)

Разверните пункт **Element 1** (Элемент 1) и настройте его следующим образом:

* В поле **Keyword** (Ключевое слово) введите **Enable Bounds Control** (Включить управление границами) для ссылки на команду Enable Bounds Control, созданную в предыдущем разделе.
* Щелкните маленький значок **+** , чтобы добавить событие.
* В окне Hierarchy (Иерархия) укажите объект **RoverExplorer** в поле **None (Object)** (Отсутствует (Объект)).
* В раскрывающемся списке **No Function** (Функция отсутствует) выберите **BoundsControl** > **bool enabled** (Активация по логическому значению), чтобы обновлять это значение свойства при срабатывании события.
* Убедитесь, что **установлен** флажок аргумента.
* Щелкните небольшой значок **+** , чтобы добавить событие.
* В окне Hierarchy (Иерархия) укажите объект **RoverExplorer** в поле **None (Object)** (Отсутствует (Объект)).
* В раскрывающемся списке **No Function** (Функция отсутствует) выберите **ObjectManipulator** > **bool enabled** (Активация по логическому значению), чтобы обновлять это значение свойства при срабатывании события.
* Убедитесь, что **установлен** флажок аргумента.

![Настройка элемента ключевого слова 1](images/mr-learning-base/base-09-section3-step1-5.png)

Разверните пункт **Element 2** (Элемент 2) и настройте его следующим образом:

* В поле **Keyword** (Ключевое слово) введите **Disable Bounds Control** (Отключить управление границами) для ссылки на команду Disable Bounds Control, созданную в предыдущем разделе.
* Щелкните маленький значок **+** , чтобы добавить событие.
* В окне Hierarchy (Иерархия) укажите объект **RoverExplorer** в поле **None (Object)** (Отсутствует (Объект)).
* В раскрывающемся списке **No Function** (Функция отсутствует) выберите **BoundsControl** > **bool enabled** (Активация по логическому значению), чтобы обновлять это значение свойства при срабатывании события.
* Убедитесь, что флажок аргумента **снят**.
* Щелкните небольшой значок **+** , чтобы добавить событие.
* В окне Hierarchy (Иерархия) укажите объект **RoverExplorer** в поле **None (Object)** (Отсутствует (Объект)).
* В раскрывающемся списке **No Function** (Функция отсутствует) выберите **ObjectManipulator** > **bool enabled** (Активация по логическому значению), чтобы обновлять это значение свойства при срабатывании события.
* Убедитесь, что флажок аргумента **снят**.

![Настройка элемента ключевого слова 2](images/mr-learning-base/base-09-section3-step1-6.png)

В окне Hierarchy (Иерархия) выберите объект RoverExplorer > **RoverAssembly**, затем в окне Inspector (Инспектор) нажмите кнопку **Add Component** (Добавить компонент), чтобы добавить компонент **SpeechInputHandler**, и настройте его следующим образом:

* Убедитесь, что флажок **Is Focus Required** (Требуется фокус) **установлен**, чтобы пользователь видел объект с компонентом SpeechInputHandler, например RoverAssembly, для активации речевой команды.
* В окне Project (Проект) добавьте заготовку **SpeechConfirmation Tooltip** в поле **Speech Confirmation Tooltip Prefab** (Заготовка подсказки подтверждения голосом), чтобы эта заготовка отображалась при распознавании речевой команды.

![Добавление обработчика речевого ввода в Rover Assembly](images/mr-learning-base/base-09-section3-step1-7.png)

В компоненте SpeechInputHandler щелкните маленький значок **+** , чтобы добавить элемент ключевого слова, разверните только что созданный элемент, а затем настройте его следующим образом:

* В поле **Keyword** (Ключевое слово) введите **Enable Tap to Place** (Включить возможность размещения касанием) для ссылки на команду Enable Tap to Place (Включить возможность размещения касанием), созданную в предыдущем разделе.
* Щелкните маленький значок **+** , чтобы добавить событие.
* В окне Hierarchy (Иерархия) укажите сам объект, т. е. тот же объект **RoverAssembly** в поле **None (Object)** (Отсутствует (Объект)).
* В раскрывающемся списке **No Function** (Функция отсутствует) выберите **TapToPlace** > **bool Enabled** (Активация по логическому значению), чтобы обновлять это значение свойства при срабатывании события.
* Убедитесь, что **установлен** флажок аргумента.

![Настройка обработчика речевого ввода в Rover Assembly](images/mr-learning-base/base-09-section3-step1-8.png)

## <a name="congratulations"></a>Поздравляем!

Из этого учебника вы узнали, как создавать речевые команды и управлять ими глобально. Вы также узнали, как управлять локальными речевыми командами, требующими от пользователя просмотра объекта, управляющего речевой командой.

На этом работа с серией [учебников по началу работы](mr-learning-base-01.md) завершена. С помощью этих учебников вы успешно создали полную среду смешанной реальности с нуля, используя MRTK.

В следующих двух сериях учебников по [Пространственным привязкам Azure](mr-learning-asa-01.md) и [многопользовательским возможностям](mr-learning-sharing-01.md) вы узнаете, как интегрировать Пространственные привязки Azure в проект, чтобы использовать опыт работы с обозревателем лунохода в реальных условиях. Затем вы узнаете, как добавлять в проект многопользовательские возможности, чтобы предоставить общий доступ к сведениям о перемещении пользователя и объекта в режиме реального времени.

## <a name="next-development-checkpoint"></a>Следующий этап разработки

Если вы следуете изложенным нами этапам разработки для Unity, вашей следующей задачей будет ознакомление с основными стандартными блоками приложений смешанной реальности.

> [!div class="nextstepaction"]
> [Базовые взаимодействия](/windows/mixed-reality/mrtk-unity/)

Вы можете в любой момент вернуться к [этапам разработки для Unity](../unity-development-overview.md#1-getting-started).
