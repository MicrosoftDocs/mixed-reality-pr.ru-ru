---
title: Контроллеры движения и жестов в DirectX
description: Приступите к работе с руководством для разработчиков, чтобы использовать контроллеры отслеживания и перемещения в собственных приложениях DirectX.
author: caseymeekhof
ms.author: cmeekhof
ms.date: 08/04/2020
ms.topic: article
keywords: руки, контроллеры движения, DirectX, ввод, голограммы, гарнитура смешанной реальности, гарнитура Windows Mixed Reality, гарнитура виртуальной реальности
ms.openlocfilehash: 843065ccc0989f9c3bc2ad494503ee46d08d0d77
ms.sourcegitcommit: d3a3b4f13b3728cfdd4d43035c806c0791d3f2fe
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/20/2021
ms.locfileid: "98580807"
---
# <a name="hands-and-motion-controllers-in-directx"></a><span data-ttu-id="2c8d5-104">Контроллеры движения и жестов в DirectX</span><span class="sxs-lookup"><span data-stu-id="2c8d5-104">Hands and motion controllers in DirectX</span></span>

> [!NOTE]
> <span data-ttu-id="2c8d5-105">Эта статья связана с устаревшими собственными API-интерфейсами WinRT.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-105">This article relates to the legacy WinRT native APIs.</span></span>  <span data-ttu-id="2c8d5-106">Для новых проектов собственных приложений рекомендуется использовать **[API опенкср](openxr-getting-started.md)**.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-106">For new native app projects, we recommend using the **[OpenXR API](openxr-getting-started.md)**.</span></span>

<span data-ttu-id="2c8d5-107">В Windows Mixed Reality входные данные и [контроллера движения](../../design/motion-controllers.md) выполняются через API-интерфейсы пространственного ввода, находящиеся в пространстве имен [Windows. UI. input. spatial](/uwp/api/windows.ui.input.spatial) .</span><span class="sxs-lookup"><span data-stu-id="2c8d5-107">In Windows Mixed Reality, both hand and [motion controller](../../design/motion-controllers.md) input is handled through the spatial input APIs, found in the [Windows.UI.Input.Spatial](/uwp/api/windows.ui.input.spatial) namespace.</span></span> <span data-ttu-id="2c8d5-108">Это позволяет легко выполнять типичные действия, такие как **Выбор** между обоими контроллерами и движениями.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-108">This enables you to easily handle common actions like **Select** presses the same way across both hands and motion controllers.</span></span>

## <a name="getting-started"></a><span data-ttu-id="2c8d5-109">Начало работы</span><span class="sxs-lookup"><span data-stu-id="2c8d5-109">Getting started</span></span>

<span data-ttu-id="2c8d5-110">Чтобы получить доступ к пространственному входу в Windows Mixed Reality, начните с интерфейса Спатиалинтерактионманажер.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-110">To access spatial input in Windows Mixed Reality, start with the SpatialInteractionManager interface.</span></span>  <span data-ttu-id="2c8d5-111">Доступ к этому интерфейсу можно получить, вызвав  [спатиалинтерактионманажер:: жетфоркуррентвиев](//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getforcurrentview), как правило, во время запуска приложения.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-111">You can access this interface by calling  [SpatialInteractionManager::GetForCurrentView](//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getforcurrentview), typically sometime during app startup.</span></span>

```cpp
using namespace winrt::Windows::UI::Input::Spatial;

SpatialInteractionManager interactionManager = SpatialInteractionManager::GetForCurrentView();
```

<span data-ttu-id="2c8d5-112">Задача Спатиалинтерактионманажер — предоставить доступ к [спатиалинтерактионсаурцес](//uwp/api/windows.ui.input.spatial.spatialinteractionsource), который представляет источник входных данных.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-112">The SpatialInteractionManager's job is to provide access to [SpatialInteractionSources](//uwp/api/windows.ui.input.spatial.spatialinteractionsource), which represent a source of input.</span></span>  <span data-ttu-id="2c8d5-113">В системе доступно три типа Спатиалинтерактионсаурцес.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-113">There are three kinds of SpatialInteractionSources available in the system.</span></span>
* <span data-ttu-id="2c8d5-114">**Рука** — это обнаруженная пользователем рука.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-114">**Hand** represents a user's detected hand.</span></span> <span data-ttu-id="2c8d5-115">Источники руки предлагают различные функции, основанные на устройстве, от базовых жестов на HoloLens до полностью четкого отслеживания в HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-115">Hand sources offer different features based on the device, ranging from basic gestures on HoloLens to fully articulated hand tracking on HoloLens 2.</span></span> 
* <span data-ttu-id="2c8d5-116">**Контроллер** представляет сопряженный контроллер движения.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-116">**Controller** represents a paired motion controller.</span></span> <span data-ttu-id="2c8d5-117">Контроллеры движения могут предоставлять различные возможности, например триггеры, кнопки меню, кнопки, сенсорные панели и сумбстиккс.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-117">Motion controllers can offer different capabilities, for example, Select triggers, Menu buttons, Grasp buttons, touchpads, and thumbsticks.</span></span>
* <span data-ttu-id="2c8d5-118">**Voice** представляет голосовые сообщения пользователя, обнаруженные системой.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-118">**Voice** represents the user's voice speaking system-detected keywords.</span></span> <span data-ttu-id="2c8d5-119">Например, этот источник будет включать выбор и освобождение при каждом нажатии пользователем кнопки "Select".</span><span class="sxs-lookup"><span data-stu-id="2c8d5-119">For example, this source will inject a Select press and release whenever the user says "Select".</span></span>

<span data-ttu-id="2c8d5-120">Данные каждого кадра для источника представлены интерфейсом  [спатиалинтерактионсаурцестате](//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) .</span><span class="sxs-lookup"><span data-stu-id="2c8d5-120">Per-frame data for a source is represented by the  [SpatialInteractionSourceState](//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) interface.</span></span> <span data-ttu-id="2c8d5-121">Существует два разных способа доступа к этим данным в зависимости от того, требуется ли использовать основанную на событиях или опросную модель в приложении.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-121">There are two different ways to access this data, depending on whether you want to use an event-driven or polling-based model in your application.</span></span>

### <a name="event-driven-input"></a><span data-ttu-id="2c8d5-122">Входные данные, управляемые событиями</span><span class="sxs-lookup"><span data-stu-id="2c8d5-122">Event-driven input</span></span>
<span data-ttu-id="2c8d5-123">Спатиалинтерактионманажер предоставляет ряд событий, которые может прослушивать приложение.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-123">The SpatialInteractionManager provides a number of events that your app can listen for.</span></span>  <span data-ttu-id="2c8d5-124">Вот несколько примеров:   [саурцепрессед](//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed), [Саурцерелеасед и [SourceUpdated](//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourceupdated).</span><span class="sxs-lookup"><span data-stu-id="2c8d5-124">A few examples include   [SourcePressed](//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed), [SourceReleased, and [SourceUpdated](//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourceupdated).</span></span>

<span data-ttu-id="2c8d5-125">Например, следующий код подключает обработчик событий с именем MyApp:: Онсаурцепрессед к событию Саурцепрессед.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-125">For example, the following code hooks up an event handler called MyApp::OnSourcePressed to the SourcePressed event.</span></span>  <span data-ttu-id="2c8d5-126">Это позволяет приложению обнаруживать нажатия для любого типа источника взаимодействия.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-126">This allows your app to detect presses on any type of interaction source.</span></span>

```cpp
using namespace winrt::Windows::UI::Input::Spatial;

auto interactionManager = SpatialInteractionManager::GetForCurrentView();
interactionManager.SourcePressed({ this, &MyApp::OnSourcePressed });

```

<span data-ttu-id="2c8d5-127">Это нажатое событие будет отправлено в приложение асинхронно, вместе с соответствующим Спатиалинтерактионсаурцестате на момент нажатия.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-127">This pressed event is sent to your app asynchronously, along with the corresponding SpatialInteractionSourceState at the time the press happened.</span></span> <span data-ttu-id="2c8d5-128">Приложение или модуль игры могут начать обработку немедленно или поставить в очередь данные событий в подсистеме обработки входных данных.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-128">Your app or game engine may want to start processing right away or queue up the event data in your input processing routine.</span></span> <span data-ttu-id="2c8d5-129">Ниже приведена функция обработчика событий для события Саурцепрессед, которая проверяет, была ли нажата кнопка выбора.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-129">Here's an event handler function for the SourcePressed event, which checks whether the select button has been pressed.</span></span>

```cpp
using namespace winrt::Windows::UI::Input::Spatial;

void MyApp::OnSourcePressed(SpatialInteractionManager const& sender, SpatialInteractionSourceEventArgs const& args)
{
    if (args.PressKind() == SpatialInteractionPressKind::Select)
    {
        // Select button was pressed, update app state
    }
}
```

<span data-ttu-id="2c8d5-130">Приведенный выше код проверяет только нажатие клавиши "Select", которое соответствует основному действию на устройстве.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-130">The above code only checks for the 'Select' press, which corresponds to the primary action on the device.</span></span> <span data-ttu-id="2c8d5-131">Примеры включают в себя выполнение Аиртап в HoloLens или извлечение триггера в контроллере движения.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-131">Examples include doing an AirTap on HoloLens or pulling the trigger on a motion controller.</span></span>  <span data-ttu-id="2c8d5-132">Нажатия клавиши "Select" представляют намерение пользователя активировать голограмму, для которой они нацелены.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-132">'Select' presses represent the user's intention to activate the hologram they're targeting.</span></span>  <span data-ttu-id="2c8d5-133">Событие Саурцепрессед будет срабатывать на несколько различных кнопок и жестов, и вы можете проверить другие свойства в Спатиалинтерактионсаурце, чтобы проверить их в этих случаях.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-133">The SourcePressed event will fire for a number of different buttons and gestures, and you can inspect other properties on the SpatialInteractionSource to test for those cases.</span></span>

### <a name="polling-based-input"></a><span data-ttu-id="2c8d5-134">Входные данные на основе опроса</span><span class="sxs-lookup"><span data-stu-id="2c8d5-134">Polling-based input</span></span>
<span data-ttu-id="2c8d5-135">Можно также использовать Спатиалинтерактионманажер для опроса текущего состояния входных данных каждого кадра.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-135">You can also use SpatialInteractionManager to poll for the current state of input every frame.</span></span>  <span data-ttu-id="2c8d5-136">Для этого вызовите [жетдетектедсаурцесаттиместамп](//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getdetectedsourcesattimestamp) для каждого кадра.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-136">To do this, call [GetDetectedSourcesAtTimestamp](//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getdetectedsourcesattimestamp) every frame.</span></span>  <span data-ttu-id="2c8d5-137">Эта функция возвращает массив, содержащий один [спатиалинтерактионсаурцестате](//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) для каждого активного [спатиалинтерактионсаурце](//uwp/api/windows.ui.input.spatial.spatialinteractionsource).</span><span class="sxs-lookup"><span data-stu-id="2c8d5-137">This function returns an array containing one [SpatialInteractionSourceState](//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) for every active [SpatialInteractionSource](//uwp/api/windows.ui.input.spatial.spatialinteractionsource).</span></span> <span data-ttu-id="2c8d5-138">Это означает, что по одному для каждого активного контроллера движения, по одному для каждой контрольной руки, и один для речи, если команда "Select" недавно распространенная.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-138">This means one for each active motion controller, one for each tracked hand, and one for speech if a 'select' command was recently uttered.</span></span> <span data-ttu-id="2c8d5-139">Затем можно проверить свойства каждого Спатиалинтерактионсаурцестате, чтобы ввести входные данные в приложение.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-139">You can then inspect the properties on each SpatialInteractionSourceState to drive input into your application.</span></span> 

<span data-ttu-id="2c8d5-140">Ниже приведен пример того, как проверить действие "Select" с помощью метода опроса.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-140">Here's an example of how to check for the 'select' action using the polling method.</span></span> <span data-ttu-id="2c8d5-141">Переменная *прогноза* представляет объект [холографикфрамепредиктион](//uwp/api/Windows.Graphics.Holographic.HolographicFramePrediction) , который можно получить из [холографикфраме](//uwp/api/windows.graphics.holographic.holographicframe).</span><span class="sxs-lookup"><span data-stu-id="2c8d5-141">The *prediction* variable represents a [HolographicFramePrediction](//uwp/api/Windows.Graphics.Holographic.HolographicFramePrediction) object, which can be obtained from the [HolographicFrame](//uwp/api/windows.graphics.holographic.holographicframe).</span></span>

```cpp
using namespace winrt::Windows::UI::Input::Spatial;

auto interactionManager = SpatialInteractionManager::GetForCurrentView();
auto sourceStates = m_spatialInteractionManager.GetDetectedSourcesAtTimestamp(prediction.Timestamp());

for (auto& sourceState : sourceStates)
{
    if (sourceState.IsSelectPressed())
    {
        // Select button is down, update app state
    }
}
```

<span data-ttu-id="2c8d5-142">Каждый Спатиалинтерактионсаурце имеет идентификатор, который можно использовать для идентификации новых источников и корреляции существующих источников от Frame к кадру.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-142">Each SpatialInteractionSource has an ID, which you can use to identify new sources and correlate existing sources from frame to frame.</span></span>  <span data-ttu-id="2c8d5-143">Каждый раз, когда они оставляют и вводят фов, получают новый идентификатор, но идентификаторы контроллеров остаются статическими в течение сеанса.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-143">Hands get a new ID every time they leave and enter the FOV, but controller IDs remain static for the duration of the session.</span></span>  <span data-ttu-id="2c8d5-144">События в Спатиалинтерактионманажер, такие как [саурцедетектед](//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcedetected) и [саурцелост](//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcelost), можно использовать для реагирования на ввод или выход из представления устройства, а также при включении или отключении контроллеров движения, а также при установке парных или непарных.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-144">You can use the events on SpatialInteractionManager such as [SourceDetected](//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcedetected) and [SourceLost](//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcelost), to react when hands enter or leave the device's view, or when motion controllers are turned on/off or are paired/unpaired.</span></span>

### <a name="predicted-vs-historical-poses"></a><span data-ttu-id="2c8d5-145">Прогнозируемые и исторические</span><span class="sxs-lookup"><span data-stu-id="2c8d5-145">Predicted vs. historical poses</span></span>
<span data-ttu-id="2c8d5-146">Жетдетектедсаурцесаттиместамп имеет параметр timestamp.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-146">GetDetectedSourcesAtTimestamp has a timestamp parameter.</span></span> <span data-ttu-id="2c8d5-147">Это позволяет запрашивать прогнозируемые или исторические данные о состоянии и представлении, позволяя сопоставлять пространственные взаимодействия с другими источниками входных данных.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-147">This enables you to request state and pose data that is either predicted or historical, letting you correlate spatial interactions with other sources of input.</span></span> <span data-ttu-id="2c8d5-148">Например, при визуализации расположения руки в текущем кадре можно передать прогнозируемую метку времени, предоставляемую [холографикфраме](//uwp/api/windows.graphics.holographic.holographicframe).</span><span class="sxs-lookup"><span data-stu-id="2c8d5-148">For example, when rendering the hand's position in the current frame, you can pass in the predicted timestamp provided by the [HolographicFrame](//uwp/api/windows.graphics.holographic.holographicframe).</span></span> <span data-ttu-id="2c8d5-149">Это позволяет системе пересылать прогнозы по положению руки, чтобы точно согласовать их с визуализированным выходным кадром, минимизируя наблюдаемую задержку.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-149">This enables the system to forward-predict the hand position to closely align with the rendered frame output, minimizing perceived latency.</span></span>

<span data-ttu-id="2c8d5-150">Однако такой прогнозируемый объект не создает идеальный указывающий луч для нацеливания на источник взаимодействия.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-150">However, such a predicted pose doesn't produce an ideal pointing ray for targeting with an interaction source.</span></span> <span data-ttu-id="2c8d5-151">Например, при нажатии кнопки "контроллер движения" может пройти до 20 мс, чтобы это событие было восходящей через Bluetooth для операционной системы.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-151">For example, when a motion controller button is pressed, it can take up to 20 ms for that event to bubble up through Bluetooth to the operating system.</span></span> <span data-ttu-id="2c8d5-152">Аналогично, после того, как пользователь выполняет жест, может пройти некоторое время, прежде чем система обнаружит жест, а приложение запрашивает его.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-152">Similarly, after a user does a hand gesture, some amount of time may pass before the system detects the gesture and your app then polls for it.</span></span> <span data-ttu-id="2c8d5-153">К моменту, когда приложение опрашивается об изменении состояния, головной элемент и рука, используемые для этого, в действительности происходили в прошлом.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-153">By the time your app polls for a state change, the head and hand poses used to target that interaction actually happened in the past.</span></span> <span data-ttu-id="2c8d5-154">Если вы намерены передать метку времени текущей Холографикфраме в Жетдетектедсаурцесаттиместамп, то она будет перенаправлена на целевой луч во время отображения кадра, что может быть более 20 мс в будущем.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-154">If you target by passing your current HolographicFrame's timestamp to GetDetectedSourcesAtTimestamp, the pose will instead be forward predicted to the targeting ray at the time the frame will be displayed, which could be more than 20 ms in the future.</span></span> <span data-ttu-id="2c8d5-155">Эта будущая версия является хорошей для *подготовки к просмотру* источника взаимодействия, но создает задачу по *времени для взаимодействия* , так как нацеливание пользователя происходило в прошлом.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-155">This future pose is good for *rendering* the interaction source, but compounds our time problem for *targeting* the interaction, as the user's targeting occurred in the past.</span></span>

<span data-ttu-id="2c8d5-156">К счастью, события [саурцепрессед](//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed), [Саурцерелеасед и [SourceUpdated](//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourceupdated) предоставляют исторические [состояния](//uwp/api/windows.ui.input.spatial.spatialinteractionsourceeventargs.state) , связанные с каждым входным событием.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-156">Fortunately, the [SourcePressed](//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed), [SourceReleased, and [SourceUpdated](//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourceupdated) events provide the historical [State](//uwp/api/windows.ui.input.spatial.spatialinteractionsourceeventargs.state) associated with each input event.</span></span>  <span data-ttu-id="2c8d5-157">Это напрямую включает в себя главную и руки с предысторией, доступные через [трижетпоинтерпосе](//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygetpointerpose), а также историческую [метку времени](//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.timestamp) , которую можно передать другим API-интерфейсам для сопоставления с этим событием.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-157">This directly includes the historical head and hand poses available through [TryGetPointerPose](//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygetpointerpose), along with a historical [Timestamp](//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.timestamp) that you can pass to other APIs to correlate with this event.</span></span>

<span data-ttu-id="2c8d5-158">Это приводит к следующим рекомендациям при визуализации и нацеливании на руки и контроллеры каждого кадра:</span><span class="sxs-lookup"><span data-stu-id="2c8d5-158">That leads to the following best practices when rendering and targeting with hands and controllers each frame:</span></span>
* <span data-ttu-id="2c8d5-159">Для **отрисовки вручную или контроллера** каждого кадра приложение должно **опрашиваться** за **однонаправленную прогнозную** часть каждого источника взаимодействия на время Photon текущего кадра.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-159">For **hand/controller rendering** each frame, your app should **poll** for the **forward-predicted** pose of each interaction source at the current frame’s photon time.</span></span>  <span data-ttu-id="2c8d5-160">Можно опросить все источники взаимодействия, вызвав [жетдетектедсаурцесаттиместамп](//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getdetectedsourcesattimestamp) каждый кадр, передав прогнозируемую отметку времени, предоставленную [Холографикфраме:: куррентпредиктион](//uwp/api/windows.graphics.holographic.holographicframe.currentprediction).</span><span class="sxs-lookup"><span data-stu-id="2c8d5-160">You can poll for all interaction sources by calling [GetDetectedSourcesAtTimestamp](//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getdetectedsourcesattimestamp) each frame, passing in the predicted timestamp provided by [HolographicFrame::CurrentPrediction](//uwp/api/windows.graphics.holographic.holographicframe.currentprediction).</span></span>
* <span data-ttu-id="2c8d5-161">Для **целей или контроллеров, предназначенных** для пресс-релизов, приложение должно обрабатывать **события**, вызванные нажатием или выпуском, райкастинг на основе **исторической** головки или руки для этого события.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-161">For **hand/controller targeting** upon a press or release, your app should handle pressed/released **events**, raycasting based on the **historical** head or hand pose for that event.</span></span> <span data-ttu-id="2c8d5-162">Этот целевой объект можно получить, обрабатывая событие [саурцепрессед](//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed) или [саурцерелеасед](//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) , получая свойство [State](//uwp/api/windows.ui.input.spatial.spatialinteractionsourceeventargs.state) из аргументов события, а затем вызывая его метод [трижетпоинтерпосе](//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygetpointerpose) .</span><span class="sxs-lookup"><span data-stu-id="2c8d5-162">You get this targeting ray by handling the [SourcePressed](//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed) or [SourceReleased](//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) event, getting the [State](//uwp/api/windows.ui.input.spatial.spatialinteractionsourceeventargs.state) property from the event arguments, and then calling its [TryGetPointerPose](//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygetpointerpose) method.</span></span>

## <a name="cross-device-input-properties"></a><span data-ttu-id="2c8d5-163">Свойства ввода для разных устройств</span><span class="sxs-lookup"><span data-stu-id="2c8d5-163">Cross-device input properties</span></span>
<span data-ttu-id="2c8d5-164">API Спатиалинтерактионсаурце поддерживает контроллеры и системы отслеживания вручную с широким спектром возможностей.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-164">The SpatialInteractionSource API supports controllers and hand tracking systems with a wide range of capabilities.</span></span> <span data-ttu-id="2c8d5-165">Некоторые из этих возможностей являются общими для разных типов устройств.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-165">A number of these capabilities are common between device types.</span></span> <span data-ttu-id="2c8d5-166">Например, для отслеживания и контроллеров движения вручную предоставляется действие "Select" и трехмерное расположение.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-166">For example, hand tracking and motion controllers both provide a 'select' action and a 3D position.</span></span> <span data-ttu-id="2c8d5-167">Везде, где это возможно, API сопоставляет эти общие возможности тем же свойствам в Спатиалинтерактионсаурце.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-167">Wherever possible, the API maps these common capabilities to the same properties on the SpatialInteractionSource.</span></span>  <span data-ttu-id="2c8d5-168">Это позволяет приложениям более легко поддерживать широкий спектр входных типов.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-168">This enables applications to more easily support a wide range of input types.</span></span> <span data-ttu-id="2c8d5-169">В следующей таблице описаны поддерживаемые свойства и их сравнение во входных типах.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-169">The following table describes the properties that are supported, and how they compare across input types.</span></span>

| <span data-ttu-id="2c8d5-170">Свойство</span><span class="sxs-lookup"><span data-stu-id="2c8d5-170">Property</span></span> | <span data-ttu-id="2c8d5-171">Описание</span><span class="sxs-lookup"><span data-stu-id="2c8d5-171">Description</span></span> | <span data-ttu-id="2c8d5-172">Жесты HoloLens (1-го поколения)</span><span class="sxs-lookup"><span data-stu-id="2c8d5-172">HoloLens(1st gen) Gestures</span></span> | <span data-ttu-id="2c8d5-173">Контроллеры движения</span><span class="sxs-lookup"><span data-stu-id="2c8d5-173">Motion Controllers</span></span> | <span data-ttu-id="2c8d5-174">Руки с формулировкой</span><span class="sxs-lookup"><span data-stu-id="2c8d5-174">Articulated Hands</span></span>|
|--- |--- |--- |--- |--- |
| [<span data-ttu-id="2c8d5-175">Спатиалинтерактионсаурце::**правой или левой**</span><span class="sxs-lookup"><span data-stu-id="2c8d5-175">SpatialInteractionSource::**Handedness**</span></span>](//uwp/api/windows.ui.input.spatial.spatialinteractionsource.handedness) | <span data-ttu-id="2c8d5-176">Правый или левый рукой или Controller.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-176">Right or left hand / controller.</span></span> | <span data-ttu-id="2c8d5-177">Не поддерживается</span><span class="sxs-lookup"><span data-stu-id="2c8d5-177">Not Supported</span></span> | <span data-ttu-id="2c8d5-178">Поддерживается</span><span class="sxs-lookup"><span data-stu-id="2c8d5-178">Supported</span></span> | <span data-ttu-id="2c8d5-179">Поддерживается</span><span class="sxs-lookup"><span data-stu-id="2c8d5-179">Supported</span></span> |
| [<span data-ttu-id="2c8d5-180">Спатиалинтерактионсаурцестате::**исселектпрессед**</span><span class="sxs-lookup"><span data-stu-id="2c8d5-180">SpatialInteractionSourceState::**IsSelectPressed**</span></span>](//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.isselectpressed) | <span data-ttu-id="2c8d5-181">Текущее состояние основной кнопки.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-181">Current state of the primary button.</span></span> | <span data-ttu-id="2c8d5-182">Касание Air</span><span class="sxs-lookup"><span data-stu-id="2c8d5-182">Air Tap</span></span> | <span data-ttu-id="2c8d5-183">Триггер</span><span class="sxs-lookup"><span data-stu-id="2c8d5-183">Trigger</span></span> | <span data-ttu-id="2c8d5-184">Небольшое воздушное касание (вертикальное сжатие)</span><span class="sxs-lookup"><span data-stu-id="2c8d5-184">Relaxed Air Tap (upright pinch)</span></span> |
| [<span data-ttu-id="2c8d5-185">Спатиалинтерактионсаурцестате **::**</span><span class="sxs-lookup"><span data-stu-id="2c8d5-185">SpatialInteractionSourceState::**IsGrasped**</span></span>](//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.isgrasped) | <span data-ttu-id="2c8d5-186">Текущее состояние кнопки захвата.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-186">Current state of the grab button.</span></span> | <span data-ttu-id="2c8d5-187">Не поддерживается</span><span class="sxs-lookup"><span data-stu-id="2c8d5-187">Not Supported</span></span> | <span data-ttu-id="2c8d5-188">Кнопка "захватить"</span><span class="sxs-lookup"><span data-stu-id="2c8d5-188">Grab button</span></span> | <span data-ttu-id="2c8d5-189">Сжатие или закрываемая рука</span><span class="sxs-lookup"><span data-stu-id="2c8d5-189">Pinch or Closed Hand</span></span> |
| [<span data-ttu-id="2c8d5-190">Спатиалинтерактионсаурцестате::**исменупрессед**</span><span class="sxs-lookup"><span data-stu-id="2c8d5-190">SpatialInteractionSourceState::**IsMenuPressed**</span></span>](//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.ismenupressed) | <span data-ttu-id="2c8d5-191">Текущее состояние кнопки меню.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-191">Current state of the menu button.</span></span>    | <span data-ttu-id="2c8d5-192">Не поддерживается</span><span class="sxs-lookup"><span data-stu-id="2c8d5-192">Not Supported</span></span> | <span data-ttu-id="2c8d5-193">Кнопка меню</span><span class="sxs-lookup"><span data-stu-id="2c8d5-193">Menu Button</span></span> | <span data-ttu-id="2c8d5-194">Не поддерживается</span><span class="sxs-lookup"><span data-stu-id="2c8d5-194">Not Supported</span></span> |
| [<span data-ttu-id="2c8d5-195">Спатиалинтерактионсаурцелокатион::**Расположение**</span><span class="sxs-lookup"><span data-stu-id="2c8d5-195">SpatialInteractionSourceLocation::**Position**</span></span>](//uwp/api/windows.ui.input.spatial.spatialinteractionsourcelocation.position) | <span data-ttu-id="2c8d5-196">XYZ положение руки или захвата на контроллере.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-196">XYZ location of the hand or grip position on the controller.</span></span> | <span data-ttu-id="2c8d5-197">Расположение Palm</span><span class="sxs-lookup"><span data-stu-id="2c8d5-197">Palm location</span></span> | <span data-ttu-id="2c8d5-198">Заменяющая позицией захвата</span><span class="sxs-lookup"><span data-stu-id="2c8d5-198">Grip pose position</span></span> | <span data-ttu-id="2c8d5-199">Расположение Palm</span><span class="sxs-lookup"><span data-stu-id="2c8d5-199">Palm location</span></span> |
| [<span data-ttu-id="2c8d5-200">Спатиалинтерактионсаурцелокатион::**Orientation**</span><span class="sxs-lookup"><span data-stu-id="2c8d5-200">SpatialInteractionSourceLocation::**Orientation**</span></span>](//uwp/api/windows.ui.input.spatial.spatialinteractionsourcelocation.orientation) | <span data-ttu-id="2c8d5-201">Кватернион, представляющий ориентацию руки или захвата на контроллере.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-201">Quaternion representing the orientation of the hand or grip pose on the controller.</span></span> | <span data-ttu-id="2c8d5-202">Не поддерживается</span><span class="sxs-lookup"><span data-stu-id="2c8d5-202">Not Supported</span></span> | <span data-ttu-id="2c8d5-203">Ориентация на подзахват</span><span class="sxs-lookup"><span data-stu-id="2c8d5-203">Grip pose orientation</span></span> | <span data-ttu-id="2c8d5-204">Ориентация Palm</span><span class="sxs-lookup"><span data-stu-id="2c8d5-204">Palm orientation</span></span> |
| [<span data-ttu-id="2c8d5-205">Спатиалпоинтеринтерактионсаурцепосе::**Расположение**</span><span class="sxs-lookup"><span data-stu-id="2c8d5-205">SpatialPointerInteractionSourcePose::**Position**</span></span>](//uwp/api/windows.ui.input.spatial.spatialpointerinteractionsourcepose.position#Windows_UI_Input_Spatial_SpatialPointerInteractionSourcePose_Position) | <span data-ttu-id="2c8d5-206">Источник указывающего луча.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-206">Origin of the pointing ray.</span></span> | <span data-ttu-id="2c8d5-207">Не поддерживается</span><span class="sxs-lookup"><span data-stu-id="2c8d5-207">Not Supported</span></span> | <span data-ttu-id="2c8d5-208">Поддерживается</span><span class="sxs-lookup"><span data-stu-id="2c8d5-208">Supported</span></span> | <span data-ttu-id="2c8d5-209">Поддерживается</span><span class="sxs-lookup"><span data-stu-id="2c8d5-209">Supported</span></span> |
| [<span data-ttu-id="2c8d5-210">Спатиалпоинтеринтерактионсаурцепосе::**форварддиректион**</span><span class="sxs-lookup"><span data-stu-id="2c8d5-210">SpatialPointerInteractionSourcePose::**ForwardDirection**</span></span>](//uwp/api/windows.ui.input.spatial.spatialpointerinteractionsourcepose.forwarddirection#Windows_UI_Input_Spatial_SpatialPointerInteractionSourcePose_ForwardDirection) | <span data-ttu-id="2c8d5-211">Направление указывающего луча.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-211">Direction of the pointing ray.</span></span> | <span data-ttu-id="2c8d5-212">Не поддерживается</span><span class="sxs-lookup"><span data-stu-id="2c8d5-212">Not Supported</span></span> | <span data-ttu-id="2c8d5-213">Поддерживается</span><span class="sxs-lookup"><span data-stu-id="2c8d5-213">Supported</span></span> | <span data-ttu-id="2c8d5-214">Поддерживается</span><span class="sxs-lookup"><span data-stu-id="2c8d5-214">Supported</span></span> |

<span data-ttu-id="2c8d5-215">Некоторые из перечисленных выше свойств недоступны на всех устройствах, и API предоставляет средства для проверки.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-215">Some of the above properties aren't available on all devices, and the API provides a means to test for this.</span></span> <span data-ttu-id="2c8d5-216">Например, можно проверить свойство [спатиалинтерактионсаурце:: исграспсуппортед](//uwp/api/windows.ui.input.spatial.spatialinteractionsource.isgraspsupported) , чтобы определить, предоставляет ли источник действие "оценить".</span><span class="sxs-lookup"><span data-stu-id="2c8d5-216">For example, you can inspect the [SpatialInteractionSource::IsGraspSupported](//uwp/api/windows.ui.input.spatial.spatialinteractionsource.isgraspsupported) property to determine whether the source provides a grasp action.</span></span>

### <a name="grip-pose-vs-pointing-pose"></a><span data-ttu-id="2c8d5-217">Захват захвата и указание объекта a</span><span class="sxs-lookup"><span data-stu-id="2c8d5-217">Grip pose vs. pointing pose</span></span>

<span data-ttu-id="2c8d5-218">Windows Mixed Reality поддерживает контроллеры движения различными конструктивными факторами.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-218">Windows Mixed Reality supports motion controllers in different form factors.</span></span>  <span data-ttu-id="2c8d5-219">Он также поддерживает системы отслеживания с формулировками.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-219">It also supports articulated hand tracking systems.</span></span>  <span data-ttu-id="2c8d5-220">Все эти системы имеют разные связи между положением руки и естественным направлением "вперед", которое приложения должны использовать для указания или отрисовки объектов в руки пользователя.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-220">All of these systems have different relationships between the hand position and the natural "forward" direction that apps should use for pointing or rendering objects in the user's hand.</span></span>  <span data-ttu-id="2c8d5-221">Для поддержки всего этого существует два типа трехмерных объектов, предоставляемых для контроллеров отслеживания и перемещения.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-221">To support all of this, there are two types of 3D poses provided for both hand tracking and motion controllers.</span></span>  <span data-ttu-id="2c8d5-222">Первый — захват, представляющий собой точку руки пользователя.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-222">The first is grip pose, which represents the user's hand position.</span></span>  <span data-ttu-id="2c8d5-223">Второй объект указывает на объект, который представляет указывающий луч, исходящий от руки или контроллера пользователя.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-223">The second is pointing pose, which represents a pointing ray originating from the user's hand or controller.</span></span> <span data-ttu-id="2c8d5-224">Таким образом, если требуется визуализировать **руку пользователя** или **объект, хранящийся в руки пользователя**, например технологий или обойма, используйте захват a.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-224">So, if you want to render **the user's hand** or **an object held in the user's hand**, such as a sword or gun, use the grip pose.</span></span> <span data-ttu-id="2c8d5-225">Если вы хотите райкаст от контроллера или вручную, например, когда пользователь \ \* указывает на пользовательский интерфейс, используйте указывающее элемент.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-225">If you want to raycast from the controller or hand, for example when the user is \*\*pointing at UI, use the pointing pose.</span></span>

<span data-ttu-id="2c8d5-226">Доступ к **захвату** можно получить с помощью [спатиалинтерактионсаурцестате::P списке:: трижетлокатион (...)](//uwp/api/windows.ui.input.spatial.spatialinteractionsourceproperties.trygetlocation#Windows_UI_Input_Spatial_SpatialInteractionSourceProperties_TryGetLocation_Windows_Perception_Spatial_SpatialCoordinateSystem_). Он определяется следующим образом:</span><span class="sxs-lookup"><span data-stu-id="2c8d5-226">You can access the **grip pose** through [SpatialInteractionSourceState::Properties::TryGetLocation(...)](//uwp/api/windows.ui.input.spatial.spatialinteractionsourceproperties.trygetlocation#Windows_UI_Input_Spatial_SpatialInteractionSourceProperties_TryGetLocation_Windows_Perception_Spatial_SpatialCoordinateSystem_). It's defined as follows:</span></span>
* <span data-ttu-id="2c8d5-227">**Позиция захвата**: Карманный центроид при удержании контроллера естественным образом настраивается влево или вправо для центрирования места внутри захвата.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-227">The **grip position**: The palm centroid when holding the controller naturally, adjusted left or right to center the position within the grip.</span></span>
* <span data-ttu-id="2c8d5-228">**Правая ось ориентации захвата**: когда вы полностью открываете руку для формирования плоской задачи с 5-пальцем, луч, обычный для вашего кармана (вперед от левого кармана, назад от правого Palm)</span><span class="sxs-lookup"><span data-stu-id="2c8d5-228">The **grip orientation's Right axis**: When you completely open your hand to form a flat 5-finger pose, the ray that is normal to your palm (forward from left palm, backward from right palm)</span></span>
* <span data-ttu-id="2c8d5-229">**Прямая ось ориентации захвата**: когда вы частично закрываете руку (как при удержании контроллера), луч, который указывает на "Forward" через лампу, сформированную небегункными пальцами.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-229">The **grip orientation's Forward axis**: When you close your hand partially (as if holding the controller), the ray that points "forward" through the tube formed by your non-thumb fingers.</span></span>
* <span data-ttu-id="2c8d5-230">**Ось Up (вверх) для ориентации захвата**: ось Up, подразумеваемая правым и прямым определением.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-230">The **grip orientation's Up axis**: The Up axis implied by the Right and Forward definitions.</span></span>

<span data-ttu-id="2c8d5-231">Вы можете получить доступ к **указателю** с помощью [спатиалинтерактионсаурцестате::P списке:: трижетлокатион (...):: саурцепоинтерпосе](/uwp/api/windows.ui.input.spatial.spatialinteractionsourcelocation#Windows_UI_Input_Spatial_SpatialInteractionSourceLocation_SourcePointerPose) или [спатиалинтерактионсаурцестате:: TryGetPointerPose (...):: TryGetInteractionSourcePose](/uwp/api/windows.ui.input.spatial.spatialpointerpose#Windows_UI_Input_Spatial_SpatialPointerPose_TryGetInteractionSourcePose_Windows_UI_Input_Spatial_SpatialInteractionSource_).</span><span class="sxs-lookup"><span data-stu-id="2c8d5-231">You can access the **pointer pose** through [SpatialInteractionSourceState::Properties::TryGetLocation(...)::SourcePointerPose](/uwp/api/windows.ui.input.spatial.spatialinteractionsourcelocation#Windows_UI_Input_Spatial_SpatialInteractionSourceLocation_SourcePointerPose) or [SpatialInteractionSourceState::TryGetPointerPose(...)::TryGetInteractionSourcePose](/uwp/api/windows.ui.input.spatial.spatialpointerpose#Windows_UI_Input_Spatial_SpatialPointerPose_TryGetInteractionSourcePose_Windows_UI_Input_Spatial_SpatialInteractionSource_).</span></span>

## <a name="controller-specific-input-properties"></a><span data-ttu-id="2c8d5-232">Входные свойства, зависящие от контроллера</span><span class="sxs-lookup"><span data-stu-id="2c8d5-232">Controller-specific input properties</span></span>
<span data-ttu-id="2c8d5-233">Для контроллеров Спатиалинтерактионсаурце имеет свойство Controller с дополнительными возможностями.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-233">For controllers, the SpatialInteractionSource has a Controller property with additional capabilities.</span></span>
* <span data-ttu-id="2c8d5-234">**Хассумбстикк:** Если значение — true, контроллер имеет аналоговый стик.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-234">**HasThumbstick:** If true, the controller has a thumbstick.</span></span> <span data-ttu-id="2c8d5-235">Проверьте свойство [контроллерпропертиес](/uwp/api/windows.ui.input.spatial.spatialinteractioncontrollerproperties) объекта спатиалинтерактионсаурцестате, чтобы получить значения x и y аналогового стика (Сумбстикккс и сумбстикки), а также состояние нажатия (иссумбстиккпрессед).</span><span class="sxs-lookup"><span data-stu-id="2c8d5-235">Inspect the [ControllerProperties](/uwp/api/windows.ui.input.spatial.spatialinteractioncontrollerproperties) property of the SpatialInteractionSourceState to acquire the thumbstick x and y values (ThumbstickX and ThumbstickY), as well as its pressed state (IsThumbstickPressed).</span></span>
* <span data-ttu-id="2c8d5-236">**Хастаучпад:** Если значение — true, контроллер имеет сенсорную панель.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-236">**HasTouchpad:** If true, the controller has a touchpad.</span></span> <span data-ttu-id="2c8d5-237">Изучите свойство Контроллерпропертиес объекта Спатиалинтерактионсаурцестате, чтобы получить значения x и y сенсорной панели (Таучпадкс и сенсорную панель), а также узнать, касается ли пользователь сенсорной панели (Истаучпадтаучед) и если они нажаты на сенсорную панель (IsTouchpadPressed).</span><span class="sxs-lookup"><span data-stu-id="2c8d5-237">Inspect the ControllerProperties property of the SpatialInteractionSourceState to acquire the touchpad x and y values (TouchpadX and TouchpadY), and to know if the user is touching the pad (IsTouchpadTouched) and if they're pressing the touchpad down (IsTouchpadPressed).</span></span>
* <span data-ttu-id="2c8d5-238">**Симплехаптиксконтроллер:** API Симплехаптиксконтроллер для контроллера позволяет проверять возможности контроллера хаптикс, а также управлять обратной связью хаптик.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-238">**SimpleHapticsController:** The SimpleHapticsController API for the controller allows you to inspect the haptics capabilities of the controller, and it also allows you to control haptic feedback.</span></span>

<span data-ttu-id="2c8d5-239">Диапазон для сенсорной панели и аналоговый стик имеет значение от-1 до 1 для обеих осей (снизу вверх и слева направо).</span><span class="sxs-lookup"><span data-stu-id="2c8d5-239">The range for touchpad and thumbstick is -1 to 1 for both axes (from bottom to top, and from left to right).</span></span> <span data-ttu-id="2c8d5-240">Диапазон для аналогового триггера, доступ к которому осуществляется с помощью свойства Спатиалинтерактионсаурцестате:: Селектпресседвалуе, имеет диапазон от 0 до 1.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-240">The range for the analog trigger, which is accessed using the SpatialInteractionSourceState::SelectPressedValue property, has a range of 0 to 1.</span></span> <span data-ttu-id="2c8d5-241">Значение 1 соответствует значению Исселектпрессед, равному true; любое другое значение корреляции с Исселектпрессед равно false.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-241">A value of 1 correlates with IsSelectPressed being equal to true; any other value correlates with IsSelectPressed being equal to false.</span></span>

## <a name="articulated-hand-tracking"></a><span data-ttu-id="2c8d5-242">Отслеживание с формулировками</span><span class="sxs-lookup"><span data-stu-id="2c8d5-242">Articulated hand tracking</span></span>
<span data-ttu-id="2c8d5-243">API Windows Mixed Reality обеспечивает полную поддержку для наследных отслеживания, например в HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-243">The Windows Mixed Reality API provides full support for articulated hand tracking, for example on HoloLens 2.</span></span> <span data-ttu-id="2c8d5-244">Отслеживание с клавиатуры можно использовать для реализации прямой манипуляции и входных моделей с точки зрения и фиксации в приложениях.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-244">Articulated hand tracking can be used to implement direct manipulation and point-and-commit input models in your applications.</span></span> <span data-ttu-id="2c8d5-245">Его также можно использовать для создания полностью настраиваемых взаимодействий.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-245">It can also be used to author fully custom interactions.</span></span>

### <a name="hand-skeleton"></a><span data-ttu-id="2c8d5-246">Схема руки</span><span class="sxs-lookup"><span data-stu-id="2c8d5-246">Hand skeleton</span></span>
<span data-ttu-id="2c8d5-247">Отслеживание с выдвижностью предоставляет 25-общий каркас, обеспечивающий множество различных типов взаимодействий.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-247">Articulated hand tracking provides a 25 joint skeleton that enables many different types of interactions.</span></span>  <span data-ttu-id="2c8d5-248">Эта схема предоставляет пять соединений для индексов, средних и кольцевых и маленьких пальцев, четыре соединения для бегунка и один стык.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-248">The skeleton provides five joints for the index/middle/ring/little fingers, four joints for the thumb, and one wrist joint.</span></span>  <span data-ttu-id="2c8d5-249">Сочленение выступает в качестве основы иерархии.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-249">The wrist joint serves as the base of the hierarchy.</span></span> <span data-ttu-id="2c8d5-250">На следующем рисунке показана структура каркаса.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-250">The following picture illustrates the layout of the skeleton.</span></span>

![Схема руки](images/hand-skeleton.png)

<span data-ttu-id="2c8d5-252">В большинстве случаев имя каждого соединения определяется на основе кости, которую он представляет.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-252">In most cases, each joint is named based on the bone that it represents.</span></span>  <span data-ttu-id="2c8d5-253">Поскольку существует две кости на каждой объединенной версии, мы используем соглашение об именовании каждого соединения на основе дочерней кости в этом расположении.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-253">Since there are two bones at every joint, we use a convention of naming each joint based on the child bone at that location.</span></span>  <span data-ttu-id="2c8d5-254">Дочерняя кость определяется как кость дальше от себя.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-254">The child bone is defined as the bone further from the wrist.</span></span>  <span data-ttu-id="2c8d5-255">Например, соединение "index Проксимал" содержит начальную точку проксимал индекса и ориентацию этой кости.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-255">For example, the "Index Proximal" joint contains the beginning position of the index proximal bone, and the orientation of that bone.</span></span>  <span data-ttu-id="2c8d5-256">Он не содержит конечную точку кости.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-256">It doesn't contain the ending position of the bone.</span></span>  <span data-ttu-id="2c8d5-257">Если это необходимо, вы получите его из следующего совместного соединения в иерархии — «промежуточное соединение с индексом».</span><span class="sxs-lookup"><span data-stu-id="2c8d5-257">If you need that, you'd get it from the next joint in the hierarchy, the "Index Intermediate" joint.</span></span>

<span data-ttu-id="2c8d5-258">Помимо 25 иерархических соединений, система обеспечивает соединение Palm.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-258">In addition to the 25 hierarchical joints, the system provides a palm joint.</span></span>  <span data-ttu-id="2c8d5-259">Карманный ПК обычно не считается частью структуры скелетообразных.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-259">The palm isn't typically considered part of the skeletal structure.</span></span> <span data-ttu-id="2c8d5-260">Он предоставляется только в качестве удобного способа для получения общей должности и ориентации руки.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-260">It's provided only as a convenient way to get the hand's overall position and orientation.</span></span>

<span data-ttu-id="2c8d5-261">Для каждого соединения предоставляются следующие сведения:</span><span class="sxs-lookup"><span data-stu-id="2c8d5-261">The following information is provided for each joint:</span></span>

| <span data-ttu-id="2c8d5-262">Имя</span><span class="sxs-lookup"><span data-stu-id="2c8d5-262">Name</span></span> | <span data-ttu-id="2c8d5-263">Описание</span><span class="sxs-lookup"><span data-stu-id="2c8d5-263">Description</span></span> |
|--- |--- |
|<span data-ttu-id="2c8d5-264">Положение</span><span class="sxs-lookup"><span data-stu-id="2c8d5-264">Position</span></span> | <span data-ttu-id="2c8d5-265">Трехмерное положение соединения, доступное в любой запрошенной системе координат.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-265">3D position of the joint, available in any requested coordinate system.</span></span> |
|<span data-ttu-id="2c8d5-266">Orientation</span><span class="sxs-lookup"><span data-stu-id="2c8d5-266">Orientation</span></span> | <span data-ttu-id="2c8d5-267">Трехмерная ориентация кости, доступная в любой запрошенной системе координат.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-267">3D orientation of the bone, available in any requested coordinate system.</span></span> |
|<span data-ttu-id="2c8d5-268">Радиус.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-268">Radius</span></span> | <span data-ttu-id="2c8d5-269">Расстояние до поверхности обложки в связной позиции.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-269">Distance to surface of the skin at the joint position.</span></span> <span data-ttu-id="2c8d5-270">Полезно для настройки прямых взаимодействий или визуализаций, использующих ширину пальца.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-270">Useful for tuning direct interactions or visualizations that rely on finger width.</span></span> |
|<span data-ttu-id="2c8d5-271">Точность</span><span class="sxs-lookup"><span data-stu-id="2c8d5-271">Accuracy</span></span> | <span data-ttu-id="2c8d5-272">Предоставляет указание о том, насколько надежна система относительно данных этого соединения.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-272">Provides a hint on how confident the system feels about this joint's information.</span></span> |

<span data-ttu-id="2c8d5-273">Вы можете получить доступ к данным схемы руки с помощью функции в [спатиалинтерактионсаурцестате](//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span><span class="sxs-lookup"><span data-stu-id="2c8d5-273">You can access the hand skeleton data through a function on the [SpatialInteractionSourceState](//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span></span>  <span data-ttu-id="2c8d5-274">Функция называется [трижесандпосе](//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygethandpose#Windows_UI_Input_Spatial_SpatialInteractionSourceState_TryGetHandPose)и возвращает объект с именем [хандпосе](//uwp/api/windows.perception.people.handpose).</span><span class="sxs-lookup"><span data-stu-id="2c8d5-274">The function is called [TryGetHandPose](//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygethandpose#Windows_UI_Input_Spatial_SpatialInteractionSourceState_TryGetHandPose), and it returns an object called [HandPose](//uwp/api/windows.perception.people.handpose).</span></span>  <span data-ttu-id="2c8d5-275">Если источник не поддерживает сформулированные руки, эта функция возвратит значение null.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-275">If the source doesn't support articulated hands, then this function will return null.</span></span>  <span data-ttu-id="2c8d5-276">Получив Хандпосе, вы можете получить текущие соединения, вызвав [трижетжоинт](//uwp/api/windows.perception.people.handpose.trygetjoint#Windows_Perception_People_HandPose_TryGetJoint_Windows_Perception_Spatial_SpatialCoordinateSystem_Windows_Perception_People_HandJointKind_Windows_Perception_People_JointPose__), указав имя интересующего нас соединения.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-276">Once you have a HandPose, you can get current joint data by calling [TryGetJoint](//uwp/api/windows.perception.people.handpose.trygetjoint#Windows_Perception_People_HandPose_TryGetJoint_Windows_Perception_Spatial_SpatialCoordinateSystem_Windows_Perception_People_HandJointKind_Windows_Perception_People_JointPose__), with the name of the joint you're interested in.</span></span>  <span data-ttu-id="2c8d5-277">Данные возвращаются в виде структуры [жоинтпосе](//uwp/api/windows.perception.people.jointpose) .</span><span class="sxs-lookup"><span data-stu-id="2c8d5-277">The data is returned as a [JointPose](//uwp/api/windows.perception.people.jointpose) structure.</span></span>  <span data-ttu-id="2c8d5-278">Следующий код возвращает расположение Совета по индексу.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-278">The following code gets the position of the index finger tip.</span></span> <span data-ttu-id="2c8d5-279">Переменная *currentState* представляет экземпляр [спатиалинтерактионсаурцестате](//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span><span class="sxs-lookup"><span data-stu-id="2c8d5-279">The variable *currentState* represents an instance of [SpatialInteractionSourceState](//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span></span>

```cpp
using namespace winrt::Windows::Perception::People;
using namespace winrt::Windows::Foundation::Numerics;

auto handPose = currentState.TryGetHandPose();
if (handPose)
{
    JointPose joint;
    if (handPose.TryGetJoint(desiredCoordinateSystem, HandJointKind::IndexTip, joint))
    {
        float3 indexTipPosition = joint.Position;

        // Do something with the index tip position
    }
}
```

### <a name="hand-mesh"></a><span data-ttu-id="2c8d5-280">Сетка руки</span><span class="sxs-lookup"><span data-stu-id="2c8d5-280">Hand mesh</span></span>

<span data-ttu-id="2c8d5-281">API отслеживания с обобразованиями позволяет полностью деформировать сетку с треугольником.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-281">The articulated hand tracking API allows for a fully deformable triangle hand mesh.</span></span>  <span data-ttu-id="2c8d5-282">Эта сеть может Deform в реальном времени вместе с каркасом руки и полезна для визуализации и сложных физических приемов.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-282">This mesh can deform in real time along with the hand skeleton, and is useful for visualization and advanced physics techniques.</span></span>  <span data-ttu-id="2c8d5-283">Для доступа к сетке типа "рука" необходимо сначала создать объект [хандмешобсервер](//uwp/api/windows.perception.people.handmeshobserver) , вызвав [трикреатехандмешобсерверасинк](//uwp/api/windows.ui.input.spatial.spatialinteractionsource.trycreatehandmeshobserverasync) в [спатиалинтерактионсаурце](//uwp/api/windows.ui.input.spatial.spatialinteractionsource).</span><span class="sxs-lookup"><span data-stu-id="2c8d5-283">To access the hand mesh, you need to first create a [HandMeshObserver](//uwp/api/windows.perception.people.handmeshobserver) object by calling [TryCreateHandMeshObserverAsync](//uwp/api/windows.ui.input.spatial.spatialinteractionsource.trycreatehandmeshobserverasync) on the [SpatialInteractionSource](//uwp/api/windows.ui.input.spatial.spatialinteractionsource).</span></span>  <span data-ttu-id="2c8d5-284">Это необходимо сделать один раз для каждого источника, как правило, при первом его отображении.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-284">This only needs to be done once per source, typically the first time you see it.</span></span>  <span data-ttu-id="2c8d5-285">Это означает, что вы назовем эту функцию для создания объекта Хандмешобсервер каждый раз, когда руки попадает в фов.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-285">That means you'll call this function to create a HandMeshObserver object whenever a hand enters the FOV.</span></span>  <span data-ttu-id="2c8d5-286">Это асинхронная функция, поэтому вам придется поработать с рядом параллелизма.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-286">This is an async function, so you'll have to deal with a bit of concurrency here.</span></span>  <span data-ttu-id="2c8d5-287">После получения доступа можно запросить объект Хандмешобсервер для буфера индекса треугольника, вызвав [жеттрианглеиндицес](//uwp/api/windows.perception.people.handmeshobserver.gettriangleindices#Windows_Perception_People_HandMeshObserver_GetTriangleIndices_System_UInt16___).</span><span class="sxs-lookup"><span data-stu-id="2c8d5-287">Once available, you can ask the HandMeshObserver object for the triangle index buffer by calling [GetTriangleIndices](//uwp/api/windows.perception.people.handmeshobserver.gettriangleindices#Windows_Perception_People_HandMeshObserver_GetTriangleIndices_System_UInt16___).</span></span>  <span data-ttu-id="2c8d5-288">Индексы не изменяют кадр над кадром, поэтому их можно получить и кэшировать в течение времени существования источника.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-288">Indices don't change frame over frame, so you can get those once and cache them for the lifetime of the source.</span></span>  <span data-ttu-id="2c8d5-289">Индексы задаются в порядке поворота по часовой стрелке.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-289">Indices are provided in clockwise winding order.</span></span>

<span data-ttu-id="2c8d5-290">Следующий код ускоряет отсоединенный std:: Thread для создания наблюдателя сетки и извлекает буфер индекса после того, как наблюдатель сетки становится доступным.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-290">The following code spins up a detached std::thread to create the mesh observer and extracts the index buffer once the mesh observer is available.</span></span>  <span data-ttu-id="2c8d5-291">Он начинается с переменной с именем *currentState*, которая является экземпляром [спатиалинтерактионсаурцестате](//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) , представляющим отслеживающую руку.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-291">It starts from a variable called *currentState*, which is an instance of [SpatialInteractionSourceState](//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) representing a tracked hand.</span></span>

```cpp
using namespace Windows::Perception::People;

std::thread createObserverThread([this, currentState]()
{
    HandMeshObserver newHandMeshObserver = currentState.Source().TryCreateHandMeshObserverAsync().get();
    if (newHandMeshObserver)
    {
        unsigned indexCount = newHandMeshObserver.TriangleIndexCount();
        vector<unsigned short> indices(indexCount);
        newHandMeshObserver.GetTriangleIndices(indices);

        // Save the indices and handMeshObserver for later use - and use a mutex to synchronize access if needed!
     }
});
createObserverThread.detach();
```
<span data-ttu-id="2c8d5-292">Запуск отсоединенного потока — это только один вариант для обработки асинхронных вызовов.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-292">Starting a detached thread is just one option for handling async calls.</span></span>  <span data-ttu-id="2c8d5-293">Кроме того, можно использовать новые функции [co_await](//windows/uwp/cpp-and-winrt-apis/concurrency) , поддерживаемые C++/винрт.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-293">Alternatively, you could use the new [co_await](//windows/uwp/cpp-and-winrt-apis/concurrency) functionality supported by C++/WinRT.</span></span>

<span data-ttu-id="2c8d5-294">Когда у вас есть объект Хандмешобсервер, необходимо удерживать его на время активности соответствующего Спатиалинтерактионсаурце.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-294">Once you have a HandMeshObserver object, you should hold onto it for the duration that its corresponding SpatialInteractionSource is active.</span></span>  <span data-ttu-id="2c8d5-295">Затем каждый кадр можно запросить о последнем буфере вершин, который представляет руку, вызвав [жетвертексстатефорпосе](//uwp/api/windows.perception.people.handmeshobserver.getvertexstateforpose) и передав экземпляр [хандпосе](//uwp/api/windows.perception.people.handpose) , представляющий объект, для которого требуются вершины.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-295">Then each frame, you can ask it for the latest vertex buffer that represents the hand by calling [GetVertexStateForPose](//uwp/api/windows.perception.people.handmeshobserver.getvertexstateforpose) and passing in a [HandPose](//uwp/api/windows.perception.people.handpose) instance that represents the pose that you want vertices for.</span></span>  <span data-ttu-id="2c8d5-296">Каждая вершина в буфере имеет расположение и нормаль.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-296">Each vertex in the buffer has a position and a normal.</span></span>  <span data-ttu-id="2c8d5-297">Ниже приведен пример того, как получить текущий набор вершин для сетки типа «рука».</span><span class="sxs-lookup"><span data-stu-id="2c8d5-297">Here's an example of how to get the current set of vertices for a hand mesh.</span></span>  <span data-ttu-id="2c8d5-298">Как и ранее, переменная *currentState* представляет экземпляр [спатиалинтерактионсаурцестате](//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span><span class="sxs-lookup"><span data-stu-id="2c8d5-298">As before, the *currentState* variable represents an instance of [SpatialInteractionSourceState](//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span></span>

```cpp
using namespace winrt::Windows::Perception::People;

auto handPose = currentState.TryGetHandPose();
if (handPose)
{
    std::vector<HandMeshVertex> vertices(handMeshObserver.VertexCount());
    auto vertexState = handMeshObserver.GetVertexStateForPose(handPose);
    vertexState.GetVertices(vertices);

    auto meshTransform = vertexState.CoordinateSystem().TryGetTransformTo(desiredCoordinateSystem);
    if (meshTransform != nullptr)
    {
        // Do something with the vertices and mesh transform, along with the indices that you saved earlier
    }
}
```

<span data-ttu-id="2c8d5-299">В отличие от скелета соединений, интерфейс API сетки руки не позволяет указать систему координат для вершин.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-299">In contrast to skeleton joints, the hand mesh API doesn't allow you to specify a coordinate system for the vertices.</span></span>  <span data-ttu-id="2c8d5-300">Вместо этого [хандмешвертексстате](//uwp/api/windows.perception.people.handmeshvertexstate) указывает систему координат, в которой предоставляются вершины.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-300">Instead, the [HandMeshVertexState](//uwp/api/windows.perception.people.handmeshvertexstate) specifies the coordinate system that the vertices are provided in.</span></span>  <span data-ttu-id="2c8d5-301">Затем можно получить преобразование сетки, вызвав [трижеттрансформто](//uwp/api/windows.perception.spatial.spatialcoordinatesystem.trygettransformto#Windows_Perception_Spatial_SpatialCoordinateSystem_TryGetTransformTo_Windows_Perception_Spatial_SpatialCoordinateSystem_) и указав нужную систему координат.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-301">You can then get a mesh transform by calling [TryGetTransformTo](//uwp/api/windows.perception.spatial.spatialcoordinatesystem.trygettransformto#Windows_Perception_Spatial_SpatialCoordinateSystem_TryGetTransformTo_Windows_Perception_Spatial_SpatialCoordinateSystem_) and specifying the coordinate system you want.</span></span>  <span data-ttu-id="2c8d5-302">Это преобразование сетки необходимо использовать при работе с вершинами.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-302">You'll need to use this mesh transform whenever you work with the vertices.</span></span>  <span data-ttu-id="2c8d5-303">Такой подход сокращает нагрузку на ЦП, особенно если вы используете только сетку для целей визуализации.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-303">This approach reduces CPU overhead, especially if you're only using the mesh for rendering purposes.</span></span>

## <a name="gaze-and-commit-composite-gestures"></a><span data-ttu-id="2c8d5-304">Составные жесты взгляда и фиксации</span><span class="sxs-lookup"><span data-stu-id="2c8d5-304">Gaze and Commit composite gestures</span></span>
<span data-ttu-id="2c8d5-305">Для приложений, использующих входную модель "взгляд-and-Commit", особенно для HoloLens (First Gen), API-интерфейс пространственного ввода предоставляет необязательный [спатиалжестуререкогнизер](/uwp/api/Windows.UI.Input.Spatial.SpatialGestureRecognizer) , который можно использовать для включения составных жестов, построенных на основе события SELECT.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-305">For applications using the gaze-and-commit input model, particularly on HoloLens (first gen), the Spatial Input API provides an optional [SpatialGestureRecognizer](/uwp/api/Windows.UI.Input.Spatial.SpatialGestureRecognizer) that can be used to enable composite gestures built on top of the 'select' event.</span></span>  <span data-ttu-id="2c8d5-306">Выполняя маршрутизацию взаимодействия от Спатиалинтерактионманажер к Спатиалжестуререкогнизеру голограммы, приложения могут равномерно обнаруживать события касания, удержания, манипуляций и навигации по голосовым и сенсорным устройствам ввода, не требуя обработки нажатий и выпусков вручную.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-306">By routing interactions from the SpatialInteractionManager to a hologram's SpatialGestureRecognizer, apps can detect Tap, Hold, Manipulation, and Navigation events uniformly across hands, voice, and spatial input devices, without having to handle presses and releases manually.</span></span>

<span data-ttu-id="2c8d5-307">Спатиалжестуререкогнизер выполняет только минимальную неоднозначность между набором запрашиваемых жестов.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-307">SpatialGestureRecognizer does only the minimal disambiguation between the set of gestures that you request.</span></span> <span data-ttu-id="2c8d5-308">Например, если вы запрашиваете просто касание, пользователь может удерживать палец вниз, если бы они были, и касание все равно будет выполняться.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-308">For example, if you request just Tap, the user may hold their finger down as long as they like and a Tap will still occur.</span></span> <span data-ttu-id="2c8d5-309">Если вы запрашиваете касание и удержание, то спустя некоторое время, удерживая палец, жест будет передвигаться в удержание, и касание больше не будет выполняться.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-309">If you request both Tap and Hold, after about a second of holding down their finger the gesture will promote to a Hold and a Tap will no longer occur.</span></span>

<span data-ttu-id="2c8d5-310">Чтобы использовать Спатиалжестуререкогнизер, обработайте событие [Интерактиондетектед](/uwp/api/Windows.UI.Input.Spatial.SpatialInteractionManager) спатиалинтерактионманажер и захватите в нем спатиалпоинтерпосе.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-310">To use SpatialGestureRecognizer, handle the SpatialInteractionManager's [InteractionDetected](/uwp/api/Windows.UI.Input.Spatial.SpatialInteractionManager) event and grab the SpatialPointerPose exposed there.</span></span> <span data-ttu-id="2c8d5-311">Для определения того, с каким действием пользователь может взаимодействовать, используйте в голову из этого объекта заголовку пользователя из этой области.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-311">Use the user's head gaze ray from this pose to intersect with the holograms and surface meshes in the user's surroundings to determine what the user is intending to interact with.</span></span> <span data-ttu-id="2c8d5-312">Затем направьте Спатиалинтерактион в аргументах события в Спатиалжестуререкогнизер целевой голограммы с помощью метода [каптуреинтерактион](/uwp/api/Windows.UI.Input.Spatial.SpatialGestureRecognizer) .</span><span class="sxs-lookup"><span data-stu-id="2c8d5-312">Then, route the SpatialInteraction in the event arguments to the target hologram's SpatialGestureRecognizer, using its [CaptureInteraction](/uwp/api/Windows.UI.Input.Spatial.SpatialGestureRecognizer) method.</span></span> <span data-ttu-id="2c8d5-313">Это начнет интерпретировать взаимодействие в соответствии с [спатиалжестуресеттингс](/uwp/api/Windows.UI.Input.Spatial.SpatialGestureSettings) , установленным для этого распознавателя во время создания или [трисетжестуресеттингс](/uwp/api/Windows.UI.Input.Spatial.SpatialGestureRecognizer).</span><span class="sxs-lookup"><span data-stu-id="2c8d5-313">This starts interpreting that interaction according to the [SpatialGestureSettings](/uwp/api/Windows.UI.Input.Spatial.SpatialGestureSettings) set on that recognizer at creation time - or by [TrySetGestureSettings](/uwp/api/Windows.UI.Input.Spatial.SpatialGestureRecognizer).</span></span>

<span data-ttu-id="2c8d5-314">В HoloLens (первое поколение) взаимодействия и жесты должны наследовать нацеливание от заголовков пользователя, а не для отображения или взаимодействия в расположении руки.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-314">On HoloLens (first gen), interactions and gestures should derive their targeting from the user's head gaze, rather than rendering or interacting at the hand's location.</span></span> <span data-ttu-id="2c8d5-315">После запуска взаимодействия можно использовать относительные движения руки для управления жестом, как в случае манипуляции или жеста навигации.</span><span class="sxs-lookup"><span data-stu-id="2c8d5-315">Once an interaction has started, relative motions of the hand may be used to control the gesture, as with the Manipulation or Navigation gesture.</span></span>

## <a name="see-also"></a><span data-ttu-id="2c8d5-316">См. также раздел</span><span class="sxs-lookup"><span data-stu-id="2c8d5-316">See also</span></span>
* [<span data-ttu-id="2c8d5-317">Направление головы и взгляда в DirectX</span><span class="sxs-lookup"><span data-stu-id="2c8d5-317">Head and eye gaze in DirectX</span></span>](gaze-in-directx.md)
* [<span data-ttu-id="2c8d5-318">Входная модель прямого управления</span><span class="sxs-lookup"><span data-stu-id="2c8d5-318">Direct manipulation input model</span></span>](../../design/direct-manipulation.md)
* [<span data-ttu-id="2c8d5-319">Входная модель "точка-and-фиксация"</span><span class="sxs-lookup"><span data-stu-id="2c8d5-319">Point-and-commit input model</span></span>](../../design/point-and-commit.md)
* [<span data-ttu-id="2c8d5-320">Входная модель "взгляд" и "фиксация"</span><span class="sxs-lookup"><span data-stu-id="2c8d5-320">Gaze and commit input model</span></span>](../../design/gaze-and-commit.md)
* [<span data-ttu-id="2c8d5-321">Контроллеры движения</span><span class="sxs-lookup"><span data-stu-id="2c8d5-321">Motion controllers</span></span>](../../design/motion-controllers.md)